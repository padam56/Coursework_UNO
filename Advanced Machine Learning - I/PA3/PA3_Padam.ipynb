{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7ce539c1-114a-473d-9d0a-771806641d06",
      "metadata": {
        "id": "7ce539c1-114a-473d-9d0a-771806641d06"
      },
      "source": [
        "### Padam Jung Thapa\n",
        "\n",
        "# Spring 2024: CSCI 6521 - Advanced Machine Learning I - PA 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Unfortunately, the training for the STATEFUL RNN was runned only upto 18 epochs as the runtime got disconnected, and the compute units were out as it was runned it colab. But the epochs for the STATELESS is runned for whole 50 epochs. If there would have been even a more day, then I would have submitted the full epochs for the StatelFUL RNN running it through the server. Sorry for the uncomplete epochs again, so I just picked the saved model of 18 epochs and ran it."
      ],
      "metadata": {
        "id": "AS_mLlwTVoNd"
      },
      "id": "AS_mLlwTVoNd"
    },
    {
      "cell_type": "markdown",
      "id": "afbafc18-a9bb-462b-8a63-24bbbabe9474",
      "metadata": {
        "id": "afbafc18-a9bb-462b-8a63-24bbbabe9474"
      },
      "source": [
        "## 1. Load the text data from the Sentiment_Data folder and combine the files as a single text and call this as combined text sentiment_text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "j55OWwNrE6J4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ff9867-6b79-40f6-b93b-2d80fee40980"
      },
      "id": "j55OWwNrE6J4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHwrH_dnGJ0J",
        "outputId": "43ed95dc-1a90-4b9a-c749-5b526a92989d"
      },
      "id": "DHwrH_dnGJ0J",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/PA3_AML-I/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrCnJ6BbGLHk",
        "outputId": "c60336ab-7e74-4269-fff2-fb1fde3149e7"
      },
      "id": "vrCnJ6BbGLHk",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PA3_AML-I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls"
      ],
      "metadata": {
        "id": "Mc53W8LkGMwW"
      },
      "id": "Mc53W8LkGMwW",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "79c57dc3-abf9-4d2c-bf57-e0844a8343b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79c57dc3-abf9-4d2c-bf57-e0844a8343b8",
        "outputId": "644e3b21-9f98-4989-a73c-0c3be3501f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hNo GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n",
            "Go to Runtime > Change runtime and select a GPU hardware accelerator.\n"
          ]
        }
      ],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# assert tf.__version__ >= \"2.`0\"\n",
        "\n",
        "#if not tf.test.is_gpu_available():\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"nlp\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d7823d36-c970-4f91-9dc9-7b4c81111ff5",
      "metadata": {
        "id": "d7823d36-c970-4f91-9dc9-7b4c81111ff5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import walk\n",
        "current_dir = os.getcwd() # First, get the path of the working directory\n",
        "path1 =current_dir+'/Sentiment_data/negative'\n",
        "path2 =current_dir+'/Sentiment_data/positive'\n",
        "_, _, list1 = next(os.walk(path1))\n",
        "_, _, list2 = next(os.walk(path2))\n",
        "filename_with_path=current_dir+'/Sentiment_data/'+'Text_Data.txt'\n",
        "f1= open(filename_with_path,\"w+\")\n",
        "# f.close()\n",
        "for i in range(len(list1)):\n",
        "    f1= open(filename_with_path,\"a+\")\n",
        "    data=\"\"\n",
        "    f = open(path1+'/'+list1[i])\n",
        "    data=f.read()\n",
        "    f.close()\n",
        "    f = open(path2+'/'+list2[i])\n",
        "    data=data+f.read()\n",
        "    f.close()\n",
        "    f1.write(data)\n",
        "    f1.close()\n",
        "#This code creates the dataset \"Text_Data.txt\" under ./data\n",
        "path_to_file = current_dir+'/Text_Data.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = current_dir+'/Sentiment_data/Text_Data.txt'\n",
        "with open(filepath) as f:\n",
        "    sentiment_text = f.read()"
      ],
      "metadata": {
        "id": "jA-nWr-mIP-i"
      },
      "id": "jA-nWr-mIP-i",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c7374932-573e-4b13-821d-56286f6cf4f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7374932-573e-4b13-821d-56286f6cf4f2",
        "outputId": "6a4d3572-87bf-433f-c815-f796aa4eb676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \" spawn \" features good guys , bad guys , lots of fighting , bloody violence , a leather-clad machine gun chick , gooey , self-healing bullet holes , scatological humor and a man-eating monster . \n",
            "it not only appears to have been tailor made for a swarm of 12- and 13-year-old boys , it appears to have been made by them . \n",
            "in a classic example of telling and not showing , \" spawn \" opens with a truckload of mumbo jumbo about forces of darkness , forces of light and how \" men are the ones who cre\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e9676356-2c9f-45b7-ac33-dd0c981efc46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e9676356-2c9f-45b7-ac33-dd0c981efc46",
        "outputId": "e9a947fa-54c9-474a-bb9d-65f492d9c8ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\x05\\n\\x12\\x13\\x14\\x16 !\"#$%&\\'()*+,-./0123456789:;=>?@[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# number of words in the dataset\n",
        "\"\".join(sorted(set(sentiment_text.lower())))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(sentiment_text)"
      ],
      "metadata": {
        "id": "iPOWGCtDI-fr"
      },
      "id": "iPOWGCtDI-fr",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([\"Second\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBxK4seXJBVA",
        "outputId": "20536994-aae1-46ec-daf9-00d5970f50b3"
      },
      "id": "LBxK4seXJBVA",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 2, 13, 6, 8, 12]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts([[21, 6, 9, 8]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmUQMVxFJCmC",
        "outputId": "eda3dc7a-b543-4469-f7e5-6b68385477a0"
      },
      "id": "PmUQMVxFJCmC",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['b o r n']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters => max_id = 39 in this case.\n",
        "dataset_size = tokenizer.document_count # total number of characters\n",
        "dataset_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfKE-0C5JHM1",
        "outputId": "589971f1-e0ac-4686-dd2c-8eb54815885d"
      },
      "id": "qfKE-0C5JHM1",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7786004"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ed3e1bca-3983-49b1-9e66-e2223c131394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed3e1bca-3983-49b1-9e66-e2223c131394",
        "outputId": "564bb4f9-3757-45ac-8763-815ec77bf96d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\\x05\\n\\x12\\x13\\x14\\x16 !\"#$%&\\'()*+,-./0123456789:;=>?@[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~',\n",
              " 74)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# print all the unique characters in the dataset\n",
        "uniq_chars = \"\".join(sorted(set(sentiment_text.lower())))\n",
        "uniq_chars, len(uniq_chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c9b3b04-d514-401a-816d-7d42933fad68",
      "metadata": {
        "id": "6c9b3b04-d514-401a-816d-7d42933fad68"
      },
      "source": [
        "## 2. Build up a stateless character-RNN model for text generation, trained using sentiment_text and train the model for at least 50 epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "JPWmbKIlKKN5"
      },
      "id": "JPWmbKIlKKN5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6aa32d1-50ed-4a25-bb7b-73d6b55475cc",
      "metadata": {
        "id": "e6aa32d1-50ed-4a25-bb7b-73d6b55475cc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(2635493)\n",
        "tf.random.set_seed(2635493)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa0af9d-5e31-457c-9ce6-ce316df77160",
      "metadata": {
        "id": "afa0af9d-5e31-457c-9ce6-ce316df77160"
      },
      "outputs": [],
      "source": [
        "# tokenizing the sentiments_text\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(sentiment_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ab244c-22e6-427f-8d97-ef5a04e356fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73ab244c-22e6-427f-8d97-ef5a04e356fc",
        "outputId": "bda4f817-70ba-475f-c563-5768d66245d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11], [2], [12], [1], [34], [2], [19], [19], [2], [11], [5], [8]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(\"Led Zeppelin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234a5db8-1485-4172-9085-2efcfbf59382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "234a5db8-1485-4172-9085-2efcfbf59382",
        "outputId": "b0be231e-7806-4e56-ff7f-d63632763f15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['l', 'e', 'd', ' ', 'z', 'e', 'p', 'p', 'e', 'l', 'i', 'n']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([[11], [2], [12], [1], [34], [2], [19], [19], [2], [11], [5], [8]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19bc19af-036a-4878-a812-892d6d8b7c68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19bc19af-036a-4878-a812-892d6d8b7c68",
        "outputId": "8112dcf6-ebe9-4464-dab4-050e1d56ab9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7786004"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset_size = tokenizer.document_count\n",
        "dataset_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82eefcb-f922-47bb-a9ff-4abe65e8225f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82eefcb-f922-47bb-a9ff-4abe65e8225f",
        "outputId": "d84697fb-aff2-49db-8886-263aa0d2c1bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# get the number of unique characters\n",
        "max_ids = len(tokenizer.word_index)\n",
        "max_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d847333b-17d8-4e01-892f-1bc2e5872d4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d847333b-17d8-4e01-892f-1bc2e5872d4e",
        "outputId": "46872f77-774d-4e8f-9401-06f85ca5685e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 3,  6,  6, ..., 23,  0, 24])]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Encode the full dataset\n",
        "[encoded_data] = np.array(tokenizer.texts_to_sequences([sentiment_text])) - 1 # subtracted 1 so it starts from 0 rather than 1\n",
        "[encoded_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49275c03-bcf5-492c-84ea-2721e4ba53d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49275c03-bcf5-492c-84ea-2721e4ba53d4",
        "outputId": "adfb68f0-dfdd-4a59-e5e2-f3de8aa18f9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7786004"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# length of encoded data\n",
        "len(encoded_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "988ac129-4ead-42ff-9a8e-d1a3a525bcc6",
      "metadata": {
        "id": "988ac129-4ead-42ff-9a8e-d1a3a525bcc6"
      },
      "outputs": [],
      "source": [
        "train_data_size = dataset_size * 90 // 100 # 90 % of the total data\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded_data[:train_data_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f796a55-d66b-47e8-a991-14784b56e427",
      "metadata": {
        "id": "2f796a55-d66b-47e8-a991-14784b56e427"
      },
      "outputs": [],
      "source": [
        "# chopping the dataset into multiple windows\n",
        "n_steps = 100\n",
        "window_length = n_steps + 1  # target is 1 character ahead of input\n",
        "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de590597-5d2f-4806-ae17-99afe6903c3b",
      "metadata": {
        "id": "de590597-5d2f-4806-ae17-99afe6903c3b"
      },
      "outputs": [],
      "source": [
        "# convert the nested dataset into flat data set\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af745199-a253-4132-9af1-f23efe699cb9",
      "metadata": {
        "id": "af745199-a253-4132-9af1-f23efe699cb9"
      },
      "outputs": [],
      "source": [
        "# splitting dataset into batches and shuffle it\n",
        "batch_size = 64\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "559d75e1-c7fc-45a1-be13-44caba332b88",
      "metadata": {
        "id": "559d75e1-c7fc-45a1-be13-44caba332b88"
      },
      "outputs": [],
      "source": [
        "# one hot encode the dataset\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_ids), Y_batch)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01183ee2-3cdf-4cbd-acd8-95011a9cea50",
      "metadata": {
        "id": "01183ee2-3cdf-4cbd-acd8-95011a9cea50"
      },
      "outputs": [],
      "source": [
        "# add prefetch to the dataset\n",
        "dataset = dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa6b3ca-dd83-42b9-b2a0-d72a115df72d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fa6b3ca-dd83-42b9-b2a0-d72a115df72d",
        "outputId": "e6d6f302-4427-45c8-a26c-03bb900a9235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 74) (64, 100)\n"
          ]
        }
      ],
      "source": [
        "# print the shape of a batch\n",
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling stateless RNN\n",
        "\n",
        "While training a stateless RNN, it was observed that the loss function, specifically sparse categorical crossentropy, was returning NaN values, which posed issues during predictions. Consequently, I developed a callback function using keras.callbacks.Callback designed to save the model at the end of each epoch and stop the training process upon encountering NaN values. This approach also facilitates the reloading of the model from the last successful epoch, given the extensive training durations and the likelihood that the training may not reach the 50-epoch mark."
      ],
      "metadata": {
        "id": "kvzUPsB09S-8"
      },
      "id": "kvzUPsB09S-8"
    },
    {
      "cell_type": "code",
      "source": [
        "# call back funciton\n",
        "class SaveModelAndHaltTraining(keras.callbacks.Callback):\n",
        "    def __init__(self, prefix):\n",
        "        super().__init__()\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def on_epoch_end(self, epoc, logs):\n",
        "\n",
        "        epoc = epoc + 1\n",
        "        # set file name to save data\n",
        "        filename = self.prefix + \"_ep_\" + str(epoc) + \".h5\" # save the model in HDF5 format\n",
        "\n",
        "        # save model\n",
        "        print(f\"\\nSaving file: {filename}\")\n",
        "        self.model.save(filename)\n",
        "\n",
        "        loss = logs.get('loss')\n",
        "        print(f\"Epoch loss: {loss}\")\n",
        "\n",
        "        # halt training if loss is nan\n",
        "        if np.isnan(loss):\n",
        "            print(f\"\\nNaN detected at Epoch: {epoc}. Training Halted!!!\")\n",
        "            self.model.stop_training = True\n"
      ],
      "metadata": {
        "id": "7ScbUzGN9DGK"
      },
      "id": "7ScbUzGN9DGK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8f1eca-492c-4e63-8820-0cd2c0a3ccb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec8f1eca-492c-4e63-8820-0cd2c0a3ccb5",
        "outputId": "a62bd5b1-f5b3-4650-ccc4-87594af15ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.1924\n",
            "Saving file: stateless_rnn_ep_1.h5\n",
            "Epoch loss: 1.1924208402633667\n",
            "109490/109490 [==============================] - 1194s 11ms/step - loss: 1.1924\n",
            "Epoch 2/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.2934\n",
            "Saving file: stateless_rnn_ep_2.h5\n",
            "Epoch loss: 1.2934210300445557\n",
            "109490/109490 [==============================] - 1192s 11ms/step - loss: 1.2934\n",
            "Epoch 3/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.3884\n",
            "Saving file: stateless_rnn_ep_3.h5\n",
            "Epoch loss: 1.3884317874908447\n",
            "109490/109490 [==============================] - 1206s 11ms/step - loss: 1.3884\n",
            "Epoch 4/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.3980\n",
            "Saving file: stateless_rnn_ep_4.h5\n",
            "Epoch loss: 1.3979785442352295\n",
            "109490/109490 [==============================] - 1214s 11ms/step - loss: 1.3980\n",
            "Epoch 5/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.4321\n",
            "Saving file: stateless_rnn_ep_5.h5\n",
            "Epoch loss: 1.4321410655975342\n",
            "109490/109490 [==============================] - 1247s 11ms/step - loss: 1.4321\n",
            "Epoch 6/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.4684\n",
            "Saving file: stateless_rnn_ep_6.h5\n",
            "Epoch loss: 1.4684019088745117\n",
            "109490/109490 [==============================] - 1187s 11ms/step - loss: 1.4684\n",
            "Epoch 7/50\n",
            "109487/109490 [============================>.] - ETA: 0s - loss: 1.4842\n",
            "Saving file: stateless_rnn_ep_7.h5\n",
            "Epoch loss: 1.4842016696929932\n",
            "109490/109490 [==============================] - 1205s 11ms/step - loss: 1.4842\n",
            "Epoch 8/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.4949\n",
            "Saving file: stateless_rnn_ep_8.h5\n",
            "Epoch loss: 1.49485445022583\n",
            "109490/109490 [==============================] - 1310s 12ms/step - loss: 1.4949\n",
            "Epoch 9/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5420\n",
            "Saving file: stateless_rnn_ep_9.h5\n",
            "Epoch loss: 1.5419586896896362\n",
            "109490/109490 [==============================] - 1333s 12ms/step - loss: 1.5420\n",
            "Epoch 10/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5542\n",
            "Saving file: stateless_rnn_ep_10.h5\n",
            "Epoch loss: 1.5541834831237793\n",
            "109490/109490 [==============================] - 1273s 12ms/step - loss: 1.5542\n",
            "Epoch 11/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.5481\n",
            "Saving file: stateless_rnn_ep_11.h5\n",
            "Epoch loss: 1.5481334924697876\n",
            "109490/109490 [==============================] - 1300s 12ms/step - loss: 1.5481\n",
            "Epoch 12/50\n",
            "109487/109490 [============================>.] - ETA: 0s - loss: 1.5539\n",
            "Saving file: stateless_rnn_ep_12.h5\n",
            "Epoch loss: 1.5538607835769653\n",
            "109490/109490 [==============================] - 1195s 11ms/step - loss: 1.5539\n",
            "Epoch 13/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.5668\n",
            "Saving file: stateless_rnn_ep_13.h5\n",
            "Epoch loss: 1.5668119192123413\n",
            "109490/109490 [==============================] - 1189s 11ms/step - loss: 1.5668\n",
            "Epoch 14/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5691\n",
            "Saving file: stateless_rnn_ep_14.h5\n",
            "Epoch loss: 1.569149136543274\n",
            "109490/109490 [==============================] - 1189s 11ms/step - loss: 1.5691\n",
            "Epoch 15/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.5709\n",
            "Saving file: stateless_rnn_ep_15.h5\n",
            "Epoch loss: 1.57087242603302\n",
            "109490/109490 [==============================] - 1191s 11ms/step - loss: 1.5709\n",
            "Epoch 16/50\n",
            "109487/109490 [============================>.] - ETA: 0s - loss: 1.6042\n",
            "Saving file: stateless_rnn_ep_16.h5\n",
            "Epoch loss: 1.6042156219482422\n",
            "109490/109490 [==============================] - 1196s 11ms/step - loss: 1.6042\n",
            "Epoch 17/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.5987\n",
            "Saving file: stateless_rnn_ep_17.h5\n",
            "Epoch loss: 1.598695993423462\n",
            "109490/109490 [==============================] - 1185s 11ms/step - loss: 1.5987\n",
            "Epoch 18/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5925\n",
            "Saving file: stateless_rnn_ep_18.h5\n",
            "Epoch loss: 1.5924924612045288\n",
            "109490/109490 [==============================] - 1219s 11ms/step - loss: 1.5925\n",
            "Epoch 19/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.6031\n",
            "Saving file: stateless_rnn_ep_19.h5\n",
            "Epoch loss: 1.603123664855957\n",
            "109490/109490 [==============================] - 1250s 11ms/step - loss: 1.6031\n",
            "Epoch 20/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5935\n",
            "Saving file: stateless_rnn_ep_20.h5\n",
            "Epoch loss: 1.5935308933258057\n",
            "109490/109490 [==============================] - 1249s 11ms/step - loss: 1.5935\n",
            "Epoch 21/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.6125\n",
            "Saving file: stateless_rnn_ep_21.h5\n",
            "Epoch loss: 1.6125009059906006\n",
            "109490/109490 [==============================] - 1293s 12ms/step - loss: 1.6125\n",
            "Epoch 22/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.6329\n",
            "Saving file: stateless_rnn_ep_22.h5\n",
            "Epoch loss: 1.6329023838043213\n",
            "109490/109490 [==============================] - 1303s 12ms/step - loss: 1.6329\n",
            "Epoch 23/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.5984\n",
            "Saving file: stateless_rnn_ep_23.h5\n",
            "Epoch loss: 1.5984320640563965\n",
            "109490/109490 [==============================] - 1303s 12ms/step - loss: 1.5984\n",
            "Epoch 24/50\n",
            "109487/109490 [============================>.] - ETA: 0s - loss: 1.5856\n",
            "Saving file: stateless_rnn_ep_24.h5\n",
            "Epoch loss: 1.5855543613433838\n",
            "109490/109490 [==============================] - 1222s 11ms/step - loss: 1.5856\n",
            "Epoch 25/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5939\n",
            "Saving file: stateless_rnn_ep_25.h5\n",
            "Epoch loss: 1.593855619430542\n",
            "109490/109490 [==============================] - 1197s 11ms/step - loss: 1.5939\n",
            "Epoch 26/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5848\n",
            "Saving file: stateless_rnn_ep_26.h5\n",
            "Epoch loss: 1.5847630500793457\n",
            "109490/109490 [==============================] - 1198s 11ms/step - loss: 1.5848\n",
            "Epoch 27/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5861\n",
            "Saving file: stateless_rnn_ep_27.h5\n",
            "Epoch loss: 1.5861005783081055\n",
            "109490/109490 [==============================] - 1199s 11ms/step - loss: 1.5861\n",
            "Epoch 28/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.5776\n",
            "Saving file: stateless_rnn_ep_28.h5\n",
            "Epoch loss: 1.5775692462921143\n",
            "109490/109490 [==============================] - 1188s 11ms/step - loss: 1.5776\n",
            "Epoch 29/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.5765\n",
            "Saving file: stateless_rnn_ep_29.h5\n",
            "Epoch loss: 1.5765153169631958\n",
            "109490/109490 [==============================] - 1182s 11ms/step - loss: 1.5765\n",
            "Epoch 30/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5925\n",
            "Saving file: stateless_rnn_ep_30.h5\n",
            "Epoch loss: 1.5924500226974487\n",
            "109490/109490 [==============================] - 1183s 11ms/step - loss: 1.5925\n",
            "Epoch 31/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5794\n",
            "Saving file: stateless_rnn_ep_31.h5\n",
            "Epoch loss: 1.5793746709823608\n",
            "109490/109490 [==============================] - 1181s 11ms/step - loss: 1.5794\n",
            "Epoch 32/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5751\n",
            "Saving file: stateless_rnn_ep_32.h5\n",
            "Epoch loss: 1.5751183032989502\n",
            "109490/109490 [==============================] - 1183s 11ms/step - loss: 1.5751\n",
            "Epoch 33/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.5722\n",
            "Saving file: stateless_rnn_ep_33.h5\n",
            "Epoch loss: 1.5721906423568726\n",
            "109490/109490 [==============================] - 1182s 11ms/step - loss: 1.5722\n",
            "Epoch 34/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.5732\n",
            "Saving file: stateless_rnn_ep_34.h5\n",
            "Epoch loss: 1.573189616203308\n",
            "109490/109490 [==============================] - 1179s 11ms/step - loss: 1.5732\n",
            "Epoch 35/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.5664\n",
            "Saving file: stateless_rnn_ep_35.h5\n",
            "Epoch loss: 1.5663564205169678\n",
            "109490/109490 [==============================] - 1185s 11ms/step - loss: 1.5664\n",
            "Epoch 36/50\n",
            "109487/109490 [============================>.] - ETA: 0s - loss: 1.5698\n",
            "Saving file: stateless_rnn_ep_36.h5\n",
            "Epoch loss: 1.5697942972183228\n",
            "109490/109490 [==============================] - 1190s 11ms/step - loss: 1.5698\n",
            "Epoch 37/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5807\n",
            "Saving file: stateless_rnn_ep_37.h5\n",
            "Epoch loss: 1.5806970596313477\n",
            "109490/109490 [==============================] - 1202s 11ms/step - loss: 1.5807\n",
            "Epoch 38/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5911\n",
            "Saving file: stateless_rnn_ep_38.h5\n",
            "Epoch loss: 1.591076374053955\n",
            "109490/109490 [==============================] - 1183s 11ms/step - loss: 1.5911\n",
            "Epoch 39/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5796\n",
            "Saving file: stateless_rnn_ep_39.h5\n",
            "Epoch loss: 1.5796068906784058\n",
            "109490/109490 [==============================] - 1201s 11ms/step - loss: 1.5796\n",
            "Epoch 40/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.5798\n",
            "Saving file: stateless_rnn_ep_40.h5\n",
            "Epoch loss: 1.5797569751739502\n",
            "109490/109490 [==============================] - 1228s 11ms/step - loss: 1.5798\n",
            "Epoch 41/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5855\n",
            "Saving file: stateless_rnn_ep_41.h5\n",
            "Epoch loss: 1.5854859352111816\n",
            "109490/109490 [==============================] - 1221s 11ms/step - loss: 1.5855\n",
            "Epoch 42/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5941\n",
            "Saving file: stateless_rnn_ep_42.h5\n",
            "Epoch loss: 1.594104528427124\n",
            "109490/109490 [==============================] - 1173s 11ms/step - loss: 1.5941\n",
            "Epoch 43/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.5955\n",
            "Saving file: stateless_rnn_ep_43.h5\n",
            "Epoch loss: 1.5954759120941162\n",
            "109490/109490 [==============================] - 1175s 11ms/step - loss: 1.5955\n",
            "Epoch 44/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.5962\n",
            "Saving file: stateless_rnn_ep_44.h5\n",
            "Epoch loss: 1.5961707830429077\n",
            "109490/109490 [==============================] - 1179s 11ms/step - loss: 1.5962\n",
            "Epoch 45/50\n",
            "109489/109490 [============================>.] - ETA: 0s - loss: 1.6016\n",
            "Saving file: stateless_rnn_ep_45.h5\n",
            "Epoch loss: 1.6015775203704834\n",
            "109490/109490 [==============================] - 1194s 11ms/step - loss: 1.6016\n",
            "Epoch 46/50\n",
            "109486/109490 [============================>.] - ETA: 0s - loss: 1.6034\n",
            "Saving file: stateless_rnn_ep_46.h5\n",
            "Epoch loss: 1.6033813953399658\n",
            "109490/109490 [==============================] - 1169s 11ms/step - loss: 1.6034\n",
            "Epoch 47/50\n",
            "109490/109490 [==============================] - ETA: 0s - loss: 1.6064\n",
            "Saving file: stateless_rnn_ep_47.h5\n",
            "Epoch loss: 1.6063705682754517\n",
            "109490/109490 [==============================] - 1157s 11ms/step - loss: 1.6064\n",
            "Epoch 48/50\n",
            "109488/109490 [============================>.] - ETA: 0s - loss: 1.6148\n",
            "Saving file: stateless_rnn_ep_48.h5\n",
            "Epoch loss: 1.6148416996002197\n",
            "109490/109490 [==============================] - 1157s 11ms/step - loss: 1.6148\n",
            "Epoch 49/50\n",
            "109487/109490 [============================>.] - ETA: 0s - loss: 1.6217\n",
            "Saving file: stateless_rnn_ep_49.h5\n",
            "Epoch loss: 1.6216634511947632\n",
            "109490/109490 [==============================] - 1153s 11ms/step - loss: 1.6217\n",
            "Epoch 50/50\n",
            "109487/109490 [============================>.] - ETA: 0s - loss: 1.6037\n",
            "Saving file: stateless_rnn_ep_50.h5\n",
            "Epoch loss: 1.6037317514419556\n",
            "109490/109490 [==============================] - 1152s 11ms/step - loss: 1.6037\n"
          ]
        }
      ],
      "source": [
        "save_model_and_halt_training = SaveModelAndHaltTraining('stateless_rnn')\n",
        "\n",
        "# Modeling the stateless RNN\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_ids]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_ids, activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, steps_per_epoch=train_data_size // batch_size,\n",
        "                    epochs=50, callbacks=[save_model_and_halt_training])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define preprocessing function\n",
        "def preprocess(text):\n",
        "    '''\n",
        "    Tokenizes the text and one hot encodes it.\n",
        "    Parameter:\n",
        "    - text: text to be processed (string)\n",
        "    Returns:\n",
        "    - tokenized and one hot encoded text\n",
        "    '''\n",
        "\n",
        "    X = np.array(tokenizer.texts_to_sequences(text)) - 1\n",
        "\n",
        "    return tf.one_hot(X, max_ids)"
      ],
      "metadata": {
        "id": "xyv1n7lOTLxC"
      },
      "id": "xyv1n7lOTLxC",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model\n",
        "sl_model_path = 'stateless_rnn_ep_50.h5'\n",
        "loaded_sl_model = keras.models.load_model(sl_model_path)"
      ],
      "metadata": {
        "id": "PRbq6WIEOYs3"
      },
      "id": "PRbq6WIEOYs3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test models prediction on custom text\n",
        "X_new = preprocess([\"Hi, how are yo\"])\n",
        "y_pred = loaded_sl_model(X_new)"
      ],
      "metadata": {
        "id": "s6fsOFd-TKIe"
      },
      "id": "s6fsOFd-TKIe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe8QS0OSUSx5",
        "outputId": "07341ef2-a8d8-49de-a34f-44c9f62028b8"
      },
      "id": "Fe8QS0OSUSx5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 14, 74), dtype=float32, numpy=\n",
              "array([[[8.7085553e-02, 3.7312010e-01, 3.4331091e-02, ...,\n",
              "         2.8405225e-29, 1.2320271e-29, 2.4005706e-29],\n",
              "        [3.8505176e-03, 3.0409612e-02, 2.4892900e-02, ...,\n",
              "         1.1522060e-36, 2.4371925e-36, 1.5556761e-36],\n",
              "        [9.8825675e-01, 1.7205573e-03, 1.6501863e-04, ...,\n",
              "         1.5698905e-29, 1.2562754e-29, 6.0515438e-30],\n",
              "        ...,\n",
              "        [1.2671677e-04, 2.6968997e-02, 8.7144718e-02, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "        [1.0112445e-02, 2.0506488e-01, 8.0967980e-04, ...,\n",
              "         3.3335153e-37, 8.8215922e-37, 5.2585213e-36],\n",
              "        [6.7294040e-04, 2.1548308e-03, 2.2797259e-03, ...,\n",
              "         1.3809284e-30, 5.1714238e-31, 3.0775221e-30]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class = np.argmax(y_pred, axis=-1)\n",
        "text_pred = tokenizer.sequences_to_texts(y_pred_class + 1)[0][-1]"
      ],
      "metadata": {
        "id": "Bv0iSYy8UaaA"
      },
      "id": "Bv0iSYy8UaaA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W9YIwWooUw0c",
        "outputId": "580faebb-b875-42c8-9b06-8537a54aa4f9"
      },
      "id": "W9YIwWooUw0c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Build up a stateful character-RNN model for text generation, trained using sentiment_text. Train the model for at least 50 epochs. You must reset the state of the RNN before starting each epoch."
      ],
      "metadata": {
        "id": "RokZLYImVO_e"
      },
      "id": "RokZLYImVO_e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to task 2, the code is re-written to stop training if there is NaN in loss."
      ],
      "metadata": {
        "id": "LMZDMDBvVkHP"
      },
      "id": "LMZDMDBvVkHP"
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data for training Stateful RNN\n",
        "batch_size = 64\n",
        "encoded_parts = np.array_split(encoded_data[:train_data_size], batch_size)\n",
        "datasets = []\n",
        "\n",
        "for encoded_part in encoded_parts:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "    datasets.append(dataset)"
      ],
      "metadata": {
        "id": "vHHPEiM7Vjxp"
      },
      "id": "vHHPEiM7Vjxp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "dataset = dataset.repeat().map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, y_batch: (tf.one_hot(X_batch, depth=max_ids), y_batch)\n",
        ")\n",
        "dataset = dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "zq_XmfxtUxpI"
      },
      "id": "zq_XmfxtUxpI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateful_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2,\n",
        "                     batch_input_shape=[batch_size, None, max_ids]),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2, recurrent_dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_ids,\n",
        "                                                    activation='softmax'))\n",
        "])\n",
        "\n",
        "prefix = 'stateful_rnn'\n",
        "save_model_and_halt_training = SaveModelAndHaltTraining(prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG0CoN0bXgIY",
        "outputId": "26cebbc4-4cd2-4cf7-fa53-01238938a3cd"
      },
      "id": "vG0CoN0bXgIY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# callback to reset states\n",
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ],
      "metadata": {
        "id": "HwBXa4Lef79B"
      },
      "id": "HwBXa4Lef79B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateful_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "steps_per_epoch = train_data_size // batch_size // n_steps\n",
        "\n",
        "stateful_model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=50,\n",
        "                   callbacks=[save_model_and_halt_training, ResetStatesCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEhLBNr8gQvX",
        "outputId": "7242e632-d1d0-42d4-9fcc-f773123ce3c3"
      },
      "id": "KEhLBNr8gQvX",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 2.2782\n",
            "Saving file: stateful_rnn_ep_1.h5\n",
            "Epoch loss: 2.2781949043273926\n",
            "1094/1094 [==============================] - 304s 274ms/step - loss: 2.2782\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1094/1094 [==============================] - ETA: 0s - loss: 2.2559\n",
            "Saving file: stateful_rnn_ep_2.h5\n",
            "Epoch loss: 2.255906820297241\n",
            "1094/1094 [==============================] - 300s 275ms/step - loss: 2.2559\n",
            "Epoch 3/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 2.0347\n",
            "Saving file: stateful_rnn_ep_3.h5\n",
            "Epoch loss: 2.0347084999084473\n",
            "1094/1094 [==============================] - 299s 274ms/step - loss: 2.0347\n",
            "Epoch 4/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.9535\n",
            "Saving file: stateful_rnn_ep_4.h5\n",
            "Epoch loss: 1.953519344329834\n",
            "1094/1094 [==============================] - 299s 274ms/step - loss: 1.9535\n",
            "Epoch 5/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.8982\n",
            "Saving file: stateful_rnn_ep_5.h5\n",
            "Epoch loss: 1.8982489109039307\n",
            "1094/1094 [==============================] - 301s 275ms/step - loss: 1.8982\n",
            "Epoch 6/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.7924\n",
            "Saving file: stateful_rnn_ep_6.h5\n",
            "Epoch loss: 1.7924405336380005\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.7924\n",
            "Epoch 7/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.7255\n",
            "Saving file: stateful_rnn_ep_7.h5\n",
            "Epoch loss: 1.7254612445831299\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.7255\n",
            "Epoch 8/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6896\n",
            "Saving file: stateful_rnn_ep_8.h5\n",
            "Epoch loss: 1.6895644664764404\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.6896\n",
            "Epoch 9/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6659\n",
            "Saving file: stateful_rnn_ep_9.h5\n",
            "Epoch loss: 1.665856122970581\n",
            "1094/1094 [==============================] - 301s 275ms/step - loss: 1.6659\n",
            "Epoch 10/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6491\n",
            "Saving file: stateful_rnn_ep_10.h5\n",
            "Epoch loss: 1.6490983963012695\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.6491\n",
            "Epoch 11/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6380\n",
            "Saving file: stateful_rnn_ep_11.h5\n",
            "Epoch loss: 1.6379919052124023\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.6380\n",
            "Epoch 12/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6283\n",
            "Saving file: stateful_rnn_ep_12.h5\n",
            "Epoch loss: 1.6283117532730103\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.6283\n",
            "Epoch 13/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6198\n",
            "Saving file: stateful_rnn_ep_13.h5\n",
            "Epoch loss: 1.6198382377624512\n",
            "1094/1094 [==============================] - 300s 275ms/step - loss: 1.6198\n",
            "Epoch 14/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6135\n",
            "Saving file: stateful_rnn_ep_14.h5\n",
            "Epoch loss: 1.6134854555130005\n",
            "1094/1094 [==============================] - 301s 275ms/step - loss: 1.6135\n",
            "Epoch 15/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6077\n",
            "Saving file: stateful_rnn_ep_15.h5\n",
            "Epoch loss: 1.6077182292938232\n",
            "1094/1094 [==============================] - 299s 274ms/step - loss: 1.6077\n",
            "Epoch 16/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.6027\n",
            "Saving file: stateful_rnn_ep_16.h5\n",
            "Epoch loss: 1.6027008295059204\n",
            "1094/1094 [==============================] - 301s 275ms/step - loss: 1.6027\n",
            "Epoch 17/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.5979\n",
            "Saving file: stateful_rnn_ep_17.h5\n",
            "Epoch loss: 1.5978846549987793\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.5979\n",
            "Epoch 18/50\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.5940\n",
            "Saving file: stateful_rnn_ep_18.h5\n",
            "Epoch loss: 1.5939885377883911\n",
            "1094/1094 [==============================] - 300s 274ms/step - loss: 1.5940\n",
            "Epoch 19/50\n",
            " 474/1094 [===========>..................] - ETA: 2:50 - loss: 1.5925"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"stateless_rnn_ep_50.h5\"\n",
        "loaded_model = keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "mFuZ7S4oQGWY"
      },
      "id": "mFuZ7S4oQGWY",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "metadata": {
        "id": "p59c2Y8zRb2l"
      },
      "id": "p59c2Y8zRb2l",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = loaded_model"
      ],
      "metadata": {
        "id": "Wwhxxg0mRjgk"
      },
      "id": "Wwhxxg0mRjgk",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = preprocess([\"How are yo\"])\n",
        "Y_pred = model.predict(X_new)\n",
        "print(Y_pred)\n",
        "Y_pred_classes = np.argmax(Y_pred, axis=-1)\n",
        "predicted_text = tokenizer.sequences_to_texts(Y_pred_classes + 1)[0][-1]  # Last character of the first sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbFTtMSQRtWw",
        "outputId": "451476cc-53fb-42db-c250-c60a39c66c68"
      },
      "id": "HbFTtMSQRtWw",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "[[[8.71104151e-02 3.73048723e-01 3.43304165e-02 1.32043451e-01\n",
            "   1.89094439e-01 1.20781772e-01 2.43124962e-02 1.15181711e-02\n",
            "   4.93453350e-03 1.02112454e-03 3.96172097e-03 4.42617340e-03\n",
            "   4.52351244e-03 1.43095374e-03 8.88224924e-04 7.08747830e-04\n",
            "   3.80122838e-05 2.64671189e-03 5.71538185e-05 1.39266439e-03\n",
            "   6.91542809e-05 2.67091492e-12 7.34530913e-04 3.89263448e-12\n",
            "   2.39440911e-18 1.61793869e-04 5.07803867e-04 4.35515467e-05\n",
            "   7.49716908e-16 6.66290653e-05 7.63402945e-14 8.34543545e-12\n",
            "   5.94975700e-06 5.61344896e-05 7.51288535e-05 1.13549009e-13\n",
            "   1.11982333e-10 5.98973822e-12 2.10037664e-11 1.31328655e-08\n",
            "   2.09435876e-12 7.86021096e-14 8.13488168e-06 5.24563461e-07\n",
            "   1.00511672e-15 1.25177201e-06 1.49210835e-11 8.37273133e-12\n",
            "   5.02569687e-12 4.43088517e-11 9.84529515e-13 2.17815106e-11\n",
            "   9.53033694e-11 5.45328409e-15 7.84426568e-09 2.70986629e-13\n",
            "   7.58134053e-33 3.62714437e-12 7.18899987e-24 6.02580458e-14\n",
            "   1.58152156e-18 1.67360026e-28 4.12726306e-28 7.00890369e-30\n",
            "   1.58608709e-28 2.83162769e-29 3.74352061e-29 2.65038474e-29\n",
            "   5.06655775e-29 8.70453473e-31 1.75810366e-29 2.83937234e-29\n",
            "   1.23157517e-29 2.39961693e-29]\n",
            "  [4.11554545e-01 2.06324330e-04 2.92561371e-02 1.28297065e-03\n",
            "   5.14093728e-04 1.43280374e-02 2.53136661e-02 1.01909982e-02\n",
            "   2.15116423e-02 8.98210332e-04 4.21767533e-02 6.47085253e-03\n",
            "   2.25845352e-03 1.03468701e-01 2.97355771e-01 4.84320801e-04\n",
            "   6.11347379e-04 1.10943736e-04 3.03475885e-04 2.96834316e-02\n",
            "   3.70856083e-04 4.81723161e-10 9.01403764e-05 2.15787301e-11\n",
            "   1.40882639e-17 2.59212538e-04 9.60121470e-05 5.55751263e-04\n",
            "   7.00182710e-14 2.98542327e-05 3.84779326e-11 7.99096761e-11\n",
            "   9.77879608e-07 5.78953361e-04 1.93580831e-06 3.03966466e-12\n",
            "   4.29641711e-10 7.58502844e-11 9.57692037e-10 3.33293499e-08\n",
            "   4.49838881e-11 5.89968477e-14 1.44467151e-07 3.51819181e-05\n",
            "   5.83888795e-17 2.45056043e-07 1.04493580e-10 2.18403498e-14\n",
            "   1.36559427e-12 9.48166212e-10 4.24707838e-12 9.09730884e-12\n",
            "   3.29168186e-11 3.87746736e-12 1.59114599e-15 2.27658580e-16\n",
            "   8.40041597e-36 2.49569837e-17 4.59765847e-37 5.11771008e-12\n",
            "   1.12649413e-22 9.76498035e-34 8.43151006e-32 7.26322898e-33\n",
            "   6.93921636e-34 1.75226110e-34 1.30245807e-34 6.77081991e-34\n",
            "   1.98933248e-34 4.26841747e-32 1.16338125e-34 1.40886258e-34\n",
            "   9.88826422e-35 1.26098987e-34]\n",
            "  [6.82800472e-01 1.08570978e-01 4.68038197e-04 4.51880433e-02\n",
            "   8.14764015e-03 1.07412115e-02 4.03409936e-02 7.63804838e-02\n",
            "   1.55648115e-04 1.01920887e-04 4.23229672e-03 2.39868998e-04\n",
            "   1.29861481e-04 3.79099930e-03 1.25385879e-04 8.39482876e-04\n",
            "   7.53570464e-04 4.32351558e-03 9.59634315e-04 3.11734434e-03\n",
            "   1.49603133e-04 1.38277612e-09 6.49060676e-05 1.87320225e-13\n",
            "   1.22346551e-16 1.67936611e-04 9.96168746e-05 7.99224526e-03\n",
            "   2.14122136e-15 7.48990033e-06 2.31352979e-12 1.18824447e-11\n",
            "   3.52192209e-09 7.08651205e-05 5.33588661e-07 5.77869932e-14\n",
            "   2.30392834e-06 2.33480813e-12 8.71007251e-06 6.34917052e-09\n",
            "   2.07489380e-13 8.96228028e-15 1.04791707e-06 1.08474715e-05\n",
            "   3.69600285e-15 1.55102152e-05 2.04193412e-10 1.45385856e-11\n",
            "   6.94746760e-10 1.05380980e-06 1.37091734e-08 3.55959386e-08\n",
            "   5.10367876e-12 2.53196994e-16 1.42067228e-12 1.97460422e-14\n",
            "   0.00000000e+00 4.48637585e-17 0.00000000e+00 1.48691226e-10\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00]\n",
            "  [1.23915379e-04 1.70668270e-02 1.55487210e-01 7.57911354e-02\n",
            "   7.05266297e-02 6.62677884e-02 4.70339432e-02 1.09772170e-02\n",
            "   2.34053135e-02 4.06765454e-02 1.25172604e-02 1.96927153e-02\n",
            "   3.62232104e-02 4.48082536e-02 1.06604462e-02 4.48109843e-02\n",
            "   1.46907642e-02 6.15672069e-03 2.13244408e-02 4.62221541e-02\n",
            "   3.36916931e-02 7.25281611e-02 5.95093099e-03 6.69886023e-02\n",
            "   2.55521038e-03 5.35942754e-03 9.85334991e-05 1.06668274e-03\n",
            "   4.55425121e-03 3.38118034e-03 8.92877206e-03 1.15457019e-02\n",
            "   3.33859971e-05 4.91195358e-04 1.37977931e-03 7.81376287e-03\n",
            "   1.83730631e-03 2.24408414e-03 2.38362409e-05 4.74994449e-04\n",
            "   7.60082097e-04 1.57246692e-03 5.13215433e-04 1.16941825e-04\n",
            "   1.51834065e-05 1.54855218e-06 1.03462871e-05 1.58085459e-06\n",
            "   1.18973455e-03 1.95324406e-04 2.30455635e-06 6.80369267e-05\n",
            "   4.13351367e-14 7.80561732e-06 3.27503540e-06 1.30890709e-04\n",
            "   0.00000000e+00 2.54959673e-07 0.00000000e+00 3.54560738e-12\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00]\n",
            "  [1.57371759e-01 1.10109730e-04 5.30239195e-02 9.95243863e-06\n",
            "   1.52331498e-03 1.05302170e-04 1.16678275e-01 2.93426514e-01\n",
            "   9.37901139e-02 3.05698672e-03 6.04289919e-02 1.00744190e-02\n",
            "   3.97412702e-02 1.69955008e-02 1.39331594e-02 3.08411587e-02\n",
            "   8.28174502e-03 6.68892404e-04 1.29267331e-02 3.52164498e-03\n",
            "   8.06134492e-02 5.30506952e-07 1.48223178e-03 1.99549305e-07\n",
            "   5.86761889e-11 4.77299705e-04 3.78160359e-04 1.68568571e-04\n",
            "   3.25572978e-06 1.19066091e-04 8.74353145e-10 2.89174181e-07\n",
            "   3.24411521e-05 5.66906601e-05 7.16128779e-05 9.23702359e-09\n",
            "   6.11845223e-08 9.27320665e-10 2.29846350e-07 1.59948939e-07\n",
            "   4.84701779e-10 3.36940024e-11 5.64167779e-09 7.68625250e-05\n",
            "   2.32937142e-10 3.77839865e-06 8.90041874e-10 1.74965407e-06\n",
            "   2.21200391e-08 9.55871471e-08 9.96093075e-09 5.29888041e-07\n",
            "   1.38045228e-13 2.79262417e-06 3.91641300e-16 1.42094880e-09\n",
            "   1.03206002e-26 8.07743369e-12 5.50710452e-30 5.99326144e-11\n",
            "   2.82557564e-28 3.62603728e-27 8.11477409e-27 3.55606632e-27\n",
            "   3.39144939e-27 8.51969855e-27 1.88507234e-26 2.24158678e-26\n",
            "   3.08574930e-26 2.40088653e-24 1.50466019e-26 1.45415029e-26\n",
            "   1.26429405e-26 8.82777800e-27]\n",
            "  [2.45792529e-04 6.60264730e-01 6.10826463e-02 7.10294629e-03\n",
            "   5.85327623e-03 1.80795759e-01 7.28827249e-03 9.83208534e-04\n",
            "   1.69046782e-02 3.59870210e-05 9.28681064e-03 4.64924332e-03\n",
            "   2.26717442e-03 1.02922309e-03 2.50961806e-04 1.20309088e-03\n",
            "   6.81724865e-03 2.89387163e-02 3.86169995e-04 1.85526151e-04\n",
            "   3.10001872e-03 4.00072668e-14 2.73585989e-04 1.47251102e-12\n",
            "   3.44269655e-18 5.14916610e-04 1.27699855e-06 5.68349196e-06\n",
            "   2.46281182e-14 7.75615699e-05 1.06846252e-14 5.92620328e-11\n",
            "   2.18227342e-05 1.43815385e-04 2.89583433e-04 1.88449478e-16\n",
            "   1.68093273e-08 7.35132119e-18 1.18189729e-11 1.46000678e-09\n",
            "   1.52637173e-17 1.84957973e-12 2.09579781e-07 9.27559896e-08\n",
            "   1.87706819e-17 1.87334983e-08 8.94876447e-12 5.22220378e-10\n",
            "   1.12236720e-10 1.19771526e-10 2.05764954e-11 1.42641357e-10\n",
            "   2.42548071e-14 7.90129906e-11 1.20081455e-14 9.54191327e-12\n",
            "   1.59550155e-35 1.21309992e-19 2.97490974e-17 4.17992329e-19\n",
            "   2.40922712e-26 3.17405085e-35 1.27160938e-33 2.92972516e-33\n",
            "   2.22860367e-34 1.08471026e-34 7.79275383e-35 1.82241185e-35\n",
            "   8.90293191e-35 7.36596300e-36 3.72283624e-35 1.05299096e-34\n",
            "   1.23457947e-34 1.56512607e-34]\n",
            "  [9.42249298e-01 1.02671352e-03 2.26237089e-03 8.51919595e-03\n",
            "   4.85512632e-04 2.28426652e-04 5.72659122e-03 9.18401033e-03\n",
            "   7.25379272e-04 8.63834342e-04 4.75945824e-04 4.27615742e-05\n",
            "   6.81696273e-03 6.33186835e-04 7.99074260e-05 1.37342804e-03\n",
            "   6.85931882e-05 5.79471374e-03 1.22705795e-04 1.84431017e-04\n",
            "   7.43448443e-04 4.08143068e-11 1.77691909e-05 3.02540870e-13\n",
            "   3.12711773e-21 3.11809214e-04 2.59421696e-03 9.23572574e-03\n",
            "   6.75595469e-15 3.25958524e-07 2.22076177e-12 2.11291706e-10\n",
            "   3.14726058e-05 7.73506108e-05 6.71751841e-05 4.19369951e-15\n",
            "   2.48581358e-07 8.45889244e-12 2.02890064e-07 3.16284371e-07\n",
            "   9.37789343e-14 3.26193182e-17 8.17960881e-06 3.71010574e-05\n",
            "   3.08176503e-19 3.04734590e-06 3.88448989e-08 1.41588172e-08\n",
            "   1.90668015e-08 7.27392990e-06 2.06246131e-09 2.46301823e-07\n",
            "   8.90363900e-14 5.91515023e-14 1.47514006e-15 4.02699696e-09\n",
            "   0.00000000e+00 3.22898596e-18 0.00000000e+00 1.74261983e-09\n",
            "   6.14658134e-30 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00]\n",
            "  [1.28703992e-04 2.76822820e-02 8.26225877e-02 6.90537766e-02\n",
            "   3.51971760e-02 3.63028198e-02 9.88998711e-02 2.90666111e-02\n",
            "   3.08808740e-02 5.28460890e-02 3.21497582e-02 3.81397717e-02\n",
            "   5.36971353e-02 6.88339099e-02 1.04802689e-02 5.72039299e-02\n",
            "   3.96070778e-02 4.92243236e-03 4.63612191e-02 3.49381901e-02\n",
            "   8.10084492e-02 2.20207889e-02 5.84116392e-03 9.43280384e-03\n",
            "   3.63479572e-04 5.15410118e-03 3.04594229e-04 4.19922930e-04\n",
            "   1.71802472e-03 9.25953593e-03 1.29059504e-03 1.08587835e-03\n",
            "   4.43711251e-05 6.15569588e-04 2.94663827e-03 5.55372704e-03\n",
            "   1.64441136e-03 3.79571429e-04 1.41250639e-05 1.25943377e-04\n",
            "   2.02211173e-04 1.71818770e-04 5.57088992e-04 1.27006715e-04\n",
            "   1.12570169e-05 8.99917779e-07 2.20583370e-05 2.27749479e-06\n",
            "   4.49248444e-04 3.19690771e-05 1.00157456e-06 1.03175400e-04\n",
            "   2.10702983e-13 9.53622839e-06 6.44161537e-06 6.56934499e-05\n",
            "   0.00000000e+00 9.77689893e-08 0.00000000e+00 5.33275572e-13\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00]\n",
            "  [1.04023246e-02 2.08215401e-01 8.24138348e-04 1.34730125e-02\n",
            "   9.39431228e-03 7.08214939e-01 3.45206074e-03 5.72468969e-04\n",
            "   1.22048175e-02 1.87310507e-03 7.53363653e-04 3.50384042e-04\n",
            "   1.65857398e-03 5.82052162e-04 1.60349756e-02 5.09799982e-04\n",
            "   3.20888248e-05 9.54425335e-03 3.44185537e-04 8.20010973e-05\n",
            "   8.79706873e-04 7.52947218e-11 1.49118292e-04 1.60738090e-09\n",
            "   1.01981100e-13 9.69635585e-05 5.20700087e-05 6.33297395e-06\n",
            "   1.23870966e-12 1.27167573e-06 2.40582970e-11 5.51356294e-09\n",
            "   5.88063699e-07 1.39276278e-06 2.61746696e-04 5.95337557e-10\n",
            "   4.07759373e-08 3.66373910e-11 9.38136040e-08 1.36275764e-08\n",
            "   2.43305837e-13 2.84670187e-11 1.51602819e-06 2.81429539e-06\n",
            "   7.95764211e-14 2.77684467e-05 9.08563415e-12 4.70738587e-11\n",
            "   5.69950798e-09 2.97011752e-07 3.25335869e-09 1.43499967e-09\n",
            "   6.56590938e-14 1.92884294e-12 6.78045309e-09 6.52115038e-15\n",
            "   0.00000000e+00 5.25997561e-16 7.45388844e-32 2.41529973e-12\n",
            "   7.04302989e-31 5.99827274e-36 1.08853125e-36 3.38407816e-33\n",
            "   1.78521503e-35 1.03068384e-35 1.93840087e-36 3.55318135e-36\n",
            "   6.17415278e-36 1.03060072e-36 2.86789806e-36 3.51142190e-37\n",
            "   9.34778449e-37 5.52329633e-36]\n",
            "  [6.67990302e-04 2.15730281e-03 2.27482268e-03 1.37376273e-03\n",
            "   1.35091424e-04 4.35828744e-03 2.75667466e-04 5.99573483e-04\n",
            "   1.53350858e-02 3.47510877e-06 1.16612573e-04 2.99247017e-06\n",
            "   1.45695813e-04 8.10027763e-04 9.68668163e-01 1.09994173e-04\n",
            "   3.74538172e-06 3.15735997e-05 3.37031524e-04 3.91317008e-04\n",
            "   8.02740513e-04 1.34354238e-11 1.07484951e-03 6.35458957e-14\n",
            "   2.26619959e-15 7.64272481e-05 3.32327227e-06 4.02424973e-07\n",
            "   5.97912561e-13 5.99013674e-07 9.16275194e-13 3.12536698e-11\n",
            "   1.26166899e-08 2.36558466e-04 7.86613583e-08 4.87097179e-13\n",
            "   2.96313465e-06 2.17927100e-11 5.17652102e-11 4.90826380e-07\n",
            "   1.11954543e-12 9.01765040e-17 6.74068758e-07 2.75482392e-08\n",
            "   2.66860509e-16 2.69256284e-09 6.79847012e-10 8.18996926e-10\n",
            "   2.23784138e-08 2.65067592e-06 9.49187284e-10 2.60611142e-08\n",
            "   4.39292886e-15 1.27755673e-12 2.31701231e-16 3.96489092e-11\n",
            "   2.69530042e-36 1.79448775e-14 0.00000000e+00 4.92628516e-09\n",
            "   7.61417330e-21 7.98402459e-30 1.41756870e-28 5.03146753e-30\n",
            "   3.63061643e-30 1.01104017e-29 1.71504701e-30 7.96315834e-30\n",
            "   3.92018489e-30 1.35808680e-29 1.18355467e-30 1.41744842e-30\n",
            "   5.30531257e-31 3.15671767e-30]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5OPyB1mRwW7",
        "outputId": "a1c3ee25-6dfc-47e2-a4aa-9cf3bf7c50d7"
      },
      "id": "G5OPyB1mRwW7",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 1, 0, 2, 1,\n",
              "        0, 1, 2, 1, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Build a function “complete_text,” which will receive two parameters:\n",
        "  - (i) a single character and\n",
        "  - (ii) temperature – and will generate text of length 100 characters."
      ],
      "metadata": {
        "id": "BmUsePd0SDxt"
      },
      "id": "BmUsePd0SDxt"
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "metadata": {
        "id": "WoOKj_NAR0zL"
      },
      "id": "WoOKj_NAR0zL",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "next_char(\"How are yo\", temperature=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FgN2nZ0rR2l5",
        "outputId": "5d067f61-f887-40b8-ecf7-71334efe9a6b"
      },
      "id": "FgN2nZ0rR2l5",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 604ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'u'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_text(text, n_chars=100, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "KJdS0nbhR4fr"
      },
      "id": "KJdS0nbhR4fr",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Run “complete_text,” which will call the stateless RNN model with three different characters: “a,” “s,” and “t” with three different temperature values of your choice and provide corresponding three different outputs."
      ],
      "metadata": {
        "id": "lyHrkm1WSz0K"
      },
      "id": "lyHrkm1WSz0K"
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"a\", temperature=0.6)) # \"a\" is the first character to start with."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY93yY9YS2ay",
        "outputId": "d6300d3c-bdd3-483b-dc19-e950cdda4759"
      },
      "id": "fY93yY9YS2ay",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 405ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "anding is the funner the film of the screent . \n",
            "the prever than anything that the paracter the film o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"s\", temperature=0.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N83tXmzTKbg",
        "outputId": "e1be38e3-2914-48de-ff42-4e1831bc2a3d"
      },
      "id": "7N83tXmzTKbg",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 557ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 290ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "s any movie is his movies and a between and hoolling is the film . \n",
            "out one for the screen the film o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"t\", temperature=0.6)) # \"t\" is the first character to start with."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6GbtvaqTTzT",
        "outputId": "0b1a05f8-a82d-49fe-c802-c7816fb701c1"
      },
      "id": "p6GbtvaqTTzT",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 509ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 1s 633ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "t him with a schole films is the show movies . \n",
            "the prever than anything that the paracter the film o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Repeat step #5 for the stateful RNN model."
      ],
      "metadata": {
        "id": "mogjSk4CTtIc"
      },
      "id": "mogjSk4CTtIc"
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"stateful_rnn_ep_18.h5\"\n",
        "loaded_model = keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "VMM2DOAYThXs"
      },
      "id": "VMM2DOAYThXs",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = loaded_model"
      ],
      "metadata": {
        "id": "lko16OHcT8zB"
      },
      "id": "lko16OHcT8zB",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"a\", temperature=0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIFjPp3kUE10",
        "outputId": "4131dd9b-304a-4efa-b9cc-93f06e4c0af5"
      },
      "id": "VIFjPp3kUE10",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 222ms/step\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 165ms/step\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "1/1 [==============================] - 0s 164ms/step\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "ak , and the story of the characters and screenplay . \n",
            "it is a strong and story because the film , an\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"s\", temperature=0.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eTyhIDuUIjS",
        "outputId": "ea8b1ed0-3aec-47f7-af10-1fe77b0cd360"
      },
      "id": "7eTyhIDuUIjS",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 217ms/step\n",
            "1/1 [==============================] - 0s 213ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "s all the tries . \n",
            "and the movie is a complete of the surprise in his did for the film . \n",
            "the things \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"t\", temperature=0.6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZBExUx3T-bK",
        "outputId": "b669ea8a-4471-4533-94bf-53456341eedc"
      },
      "id": "BZBExUx3T-bK",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 622ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "ter . \n",
            "a men and delighted in the movie who must really the film . \n",
            "where should do the movie that ma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqiVBUoEVlTQ"
      },
      "id": "pqiVBUoEVlTQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}