{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Training a Custom CNN on CIFAR-10\n",
    "\n",
    "Develop a CNN with 2-3 convolutional layers, each followed by ReLU and pooling, and 2-3 fully connected MLP layers. Use filters sized as powers of two (16-256), with odd dimensions. Select an optimizer, use batch sizes of 32-128, apply dropout and regularization, implement real-time data augmentation, and train for at least 100 epochs to evaluate testing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Setting the device to GPU 0\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single CIFAR-10 batch\n",
    "def load_batch(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        batch = pickle.load(file, encoding='bytes')\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels to one-hot encoding\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    return np.eye(num_classes)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data_batch_1: <class 'dict'>\n",
      "Keys in data_batch_1: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n"
     ]
    }
   ],
   "source": [
    "# Load a single batch\n",
    "file = '/home/pthapa2/snap/padam/Project2/cifar-10-batches-py/data_batch_1'\n",
    "data_batch_1 = load_batch(file)\n",
    "\n",
    "# Inspect the data structure\n",
    "print(f'Type of data_batch_1: {type(data_batch_1)}')\n",
    "print(f'Keys in data_batch_1: {data_batch_1.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'batch_label': <class 'bytes'>\n",
      "b'labels': <class 'list'>\n",
      "b'data': <class 'numpy.ndarray'>\n",
      "b'filenames': <class 'list'>\n",
      "Labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "for item in data_batch_1:\n",
    "    print(f'{item}: {type(data_batch_1[item])}')\n",
    "\n",
    "print('Labels:', set(data_batch_1[b'labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# Load metadata for label names\n",
    "meta_file = '/home/pthapa2/snap/padam/Project2/cifar-10-batches-py/batches.meta'\n",
    "meta_data = load_batch(meta_file)\n",
    "\n",
    "# Display label names\n",
    "print('Label names:', [name.decode('utf-8') for name in meta_data[b'label_names']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape before reshape: (50000, 3072)\n",
      "Training data shape after reshape: (50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all training batches\n",
    "all_data, all_labels = [], []\n",
    "for batch_num in range(1, 6):\n",
    "    batch_filename = f\"/home/pthapa2/snap/padam/Project2/cifar-10-batches-py/data_batch_{batch_num}\"\n",
    "    batch_data = load_batch(batch_filename)\n",
    "    all_data.append(batch_data[b'data'])\n",
    "    all_labels.extend(batch_data[b'labels'])\n",
    "\n",
    "x_train = np.vstack(all_data)\n",
    "y_train = np.array(all_labels)\n",
    "\n",
    "print(\"Training data shape before reshape:\", x_train.shape)\n",
    "x_train = x_train.reshape(len(x_train), 3, 32, 32)\n",
    "print(\"Training data shape after reshape:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, The dataset consists of 50,000 training samples, each originally having 3,072 features. These samples have been reshaped into dimensions of (50,000, 3, 32, 32), representing the format (number of samples, channels, height, width) for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for PyTorch\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train_one_hot))\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape before reshape: (10000, 3072)\n",
      "Test data shape after reshape: (10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load and process test data\n",
    "test_file = '/home/pthapa2/snap/padam/Project2/cifar-10-batches-py/test_batch'\n",
    "test_data = load_batch(test_file)\n",
    "x_test = test_data[b'data'].astype('float32') / 255.0\n",
    "y_test = np.array(test_data[b'labels'])\n",
    "print(\"Test data shape before reshape:\", x_test.shape)\n",
    "x_test = x_test.reshape(len(x_test), 3, 32, 32)\n",
    "y_test_one_hot = one_hot_encode(y_test)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test_one_hot))\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(\"Test data shape after reshape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPORTING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: Images\n",
      "Color Type: RGB\n",
      "Number of Classes: 10\n",
      "Number of Samples: 60000\n",
      "Each Sample Dimensions: (3, 32, 32)\n",
      "Training Size: 50000\n",
      "Testing Size: 10000\n"
     ]
    }
   ],
   "source": [
    "# REPORTING\n",
    "print(\"Data Type: Images\")\n",
    "print(\"Color Type: RGB\")\n",
    "print(\"Number of Classes:\", len(set(y_train)))\n",
    "print(\"Number of Samples:\", len(x_train) + len(x_test))\n",
    "print(\"Each Sample Dimensions:\", x_train.shape[1:])\n",
    "print(\"Training Size:\", len(x_train))\n",
    "print(\"Testing Size:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample image from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_sample_image(data, index=1):\n",
    "    img = data[index].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Sample Image')\n",
    "    plt.show()\n",
    "\n",
    "show_sample_image(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining real-time data augmentation transformations for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "\n",
    "# Define transformations for testing (no augmentation)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "data_dir = './data'\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomCrop(size=(32, 32), padding=4)\n",
       "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
       "               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into training and validation sets\n",
    "total_train_size = len(trainset)\n",
    "val_size = int(0.1 * total_train_size)  # 10% for validation\n",
    "train_size = total_train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_subset, val_subset = random_split(trainset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for each subset\n",
    "num_workers = 8\n",
    "trainloader = DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "valloader = DataLoader(val_subset, batch_size=128, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchsummary\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]           9,280\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 8, 8]         147,712\n",
      "         MaxPool2d-6            [-1, 256, 4, 4]               0\n",
      "            Linear-7                  [-1, 512]       2,097,664\n",
      "           Dropout-8                  [-1, 512]               0\n",
      "            Linear-9                  [-1, 128]          65,664\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,322,058\n",
      "Trainable params: 2,322,058\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 8.86\n",
      "Estimated Total Size (MB): 9.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256*4*4,512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(F.relu(self.conv3(x)))\n",
    "        x=x.view(-1 ,256 *4 *4)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiating the model \n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model0=CustomCNN().to(device)\n",
    "\n",
    "# model summary\n",
    "summary(model0,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def accuracy(predictions, labels):\n",
    "    return (predictions.argmax(dim=1) == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model0.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    for X, Y in dataloader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, Y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += (pred.argmax(dim=1) == Y).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, Y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += (pred.argmax(dim=1) == Y).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set after training is complete\n",
    "def test(dataloader, model):\n",
    "    model.eval()\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "            total_accuracy += (pred.argmax(dim=1) == Y).sum().item()\n",
    "\n",
    "    avg_accuracy = total_accuracy / len(dataloader.dataset)\n",
    "    return avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Initial Custom CNN:\n",
      "Epoch 1/100, Train Loss: 1.7827, Train Acc: 0.3309, Val Loss: 1.5528, Val Acc: 0.4304\n",
      "Epoch 2/100, Train Loss: 1.4851, Train Acc: 0.4572, Val Loss: 1.3845, Val Acc: 0.5030\n",
      "Epoch 3/100, Train Loss: 1.3275, Train Acc: 0.5186, Val Loss: 1.2847, Val Acc: 0.5392\n",
      "Epoch 4/100, Train Loss: 1.2223, Train Acc: 0.5632, Val Loss: 1.1122, Val Acc: 0.6048\n",
      "Epoch 5/100, Train Loss: 1.1286, Train Acc: 0.5992, Val Loss: 1.0945, Val Acc: 0.6198\n",
      "Epoch 6/100, Train Loss: 1.0669, Train Acc: 0.6231, Val Loss: 1.0006, Val Acc: 0.6464\n",
      "Epoch 7/100, Train Loss: 1.0175, Train Acc: 0.6392, Val Loss: 0.9604, Val Acc: 0.6666\n",
      "Epoch 8/100, Train Loss: 0.9706, Train Acc: 0.6604, Val Loss: 0.9099, Val Acc: 0.6868\n",
      "Epoch 9/100, Train Loss: 0.9338, Train Acc: 0.6724, Val Loss: 0.8982, Val Acc: 0.6940\n",
      "Epoch 10/100, Train Loss: 0.9045, Train Acc: 0.6850, Val Loss: 0.8918, Val Acc: 0.6954\n",
      "Epoch 11/100, Train Loss: 0.8805, Train Acc: 0.6942, Val Loss: 0.8244, Val Acc: 0.7198\n",
      "Epoch 12/100, Train Loss: 0.8470, Train Acc: 0.7042, Val Loss: 0.8507, Val Acc: 0.7036\n",
      "Epoch 13/100, Train Loss: 0.8455, Train Acc: 0.7053, Val Loss: 0.8163, Val Acc: 0.7238\n",
      "Epoch 14/100, Train Loss: 0.8145, Train Acc: 0.7154, Val Loss: 0.7818, Val Acc: 0.7320\n",
      "Epoch 15/100, Train Loss: 0.7946, Train Acc: 0.7217, Val Loss: 0.7711, Val Acc: 0.7328\n",
      "Epoch 16/100, Train Loss: 0.7915, Train Acc: 0.7240, Val Loss: 0.7760, Val Acc: 0.7312\n",
      "Epoch 17/100, Train Loss: 0.7783, Train Acc: 0.7290, Val Loss: 0.7916, Val Acc: 0.7334\n",
      "Epoch 18/100, Train Loss: 0.7682, Train Acc: 0.7332, Val Loss: 0.7590, Val Acc: 0.7380\n",
      "Epoch 19/100, Train Loss: 0.7573, Train Acc: 0.7364, Val Loss: 0.7846, Val Acc: 0.7350\n",
      "Epoch 20/100, Train Loss: 0.7406, Train Acc: 0.7425, Val Loss: 0.7576, Val Acc: 0.7494\n",
      "Epoch 21/100, Train Loss: 0.7304, Train Acc: 0.7466, Val Loss: 0.7214, Val Acc: 0.7498\n",
      "Epoch 22/100, Train Loss: 0.7215, Train Acc: 0.7503, Val Loss: 0.7143, Val Acc: 0.7610\n",
      "Epoch 23/100, Train Loss: 0.7163, Train Acc: 0.7493, Val Loss: 0.6958, Val Acc: 0.7580\n",
      "Epoch 24/100, Train Loss: 0.6998, Train Acc: 0.7572, Val Loss: 0.7297, Val Acc: 0.7610\n",
      "Epoch 25/100, Train Loss: 0.6975, Train Acc: 0.7595, Val Loss: 0.7159, Val Acc: 0.7600\n",
      "Epoch 26/100, Train Loss: 0.6858, Train Acc: 0.7625, Val Loss: 0.7191, Val Acc: 0.7538\n",
      "Epoch 27/100, Train Loss: 0.6847, Train Acc: 0.7631, Val Loss: 0.6850, Val Acc: 0.7666\n",
      "Epoch 28/100, Train Loss: 0.6758, Train Acc: 0.7669, Val Loss: 0.6825, Val Acc: 0.7694\n",
      "Epoch 29/100, Train Loss: 0.6694, Train Acc: 0.7687, Val Loss: 0.7008, Val Acc: 0.7744\n",
      "Epoch 30/100, Train Loss: 0.6673, Train Acc: 0.7681, Val Loss: 0.6685, Val Acc: 0.7666\n",
      "Epoch 31/100, Train Loss: 0.6618, Train Acc: 0.7702, Val Loss: 0.6991, Val Acc: 0.7588\n",
      "Epoch 32/100, Train Loss: 0.6489, Train Acc: 0.7726, Val Loss: 0.6940, Val Acc: 0.7684\n",
      "Epoch 33/100, Train Loss: 0.6518, Train Acc: 0.7738, Val Loss: 0.7063, Val Acc: 0.7612\n",
      "Epoch 34/100, Train Loss: 0.6437, Train Acc: 0.7779, Val Loss: 0.6947, Val Acc: 0.7592\n",
      "Epoch 35/100, Train Loss: 0.6349, Train Acc: 0.7777, Val Loss: 0.6849, Val Acc: 0.7660\n",
      "Epoch 36/100, Train Loss: 0.6295, Train Acc: 0.7802, Val Loss: 0.6451, Val Acc: 0.7782\n",
      "Epoch 37/100, Train Loss: 0.6257, Train Acc: 0.7836, Val Loss: 0.6703, Val Acc: 0.7682\n",
      "Epoch 38/100, Train Loss: 0.6227, Train Acc: 0.7852, Val Loss: 0.6438, Val Acc: 0.7760\n",
      "Epoch 39/100, Train Loss: 0.6207, Train Acc: 0.7871, Val Loss: 0.6373, Val Acc: 0.7854\n",
      "Epoch 40/100, Train Loss: 0.6115, Train Acc: 0.7883, Val Loss: 0.6593, Val Acc: 0.7792\n",
      "Epoch 41/100, Train Loss: 0.6151, Train Acc: 0.7881, Val Loss: 0.6569, Val Acc: 0.7716\n",
      "Epoch 42/100, Train Loss: 0.6007, Train Acc: 0.7915, Val Loss: 0.6648, Val Acc: 0.7802\n",
      "Epoch 43/100, Train Loss: 0.5998, Train Acc: 0.7926, Val Loss: 0.6080, Val Acc: 0.7968\n",
      "Epoch 44/100, Train Loss: 0.6038, Train Acc: 0.7905, Val Loss: 0.6594, Val Acc: 0.7770\n",
      "Epoch 45/100, Train Loss: 0.5941, Train Acc: 0.7924, Val Loss: 0.6582, Val Acc: 0.7794\n",
      "Epoch 46/100, Train Loss: 0.5814, Train Acc: 0.7994, Val Loss: 0.6581, Val Acc: 0.7772\n",
      "Epoch 47/100, Train Loss: 0.5862, Train Acc: 0.7970, Val Loss: 0.6359, Val Acc: 0.7880\n",
      "Epoch 48/100, Train Loss: 0.5859, Train Acc: 0.7994, Val Loss: 0.6334, Val Acc: 0.7904\n",
      "Epoch 49/100, Train Loss: 0.5804, Train Acc: 0.7986, Val Loss: 0.6276, Val Acc: 0.7910\n",
      "Epoch 50/100, Train Loss: 0.5812, Train Acc: 0.7997, Val Loss: 0.6330, Val Acc: 0.7874\n",
      "Epoch 51/100, Train Loss: 0.5718, Train Acc: 0.8003, Val Loss: 0.6401, Val Acc: 0.7838\n",
      "Epoch 52/100, Train Loss: 0.5698, Train Acc: 0.8032, Val Loss: 0.6132, Val Acc: 0.7954\n",
      "Epoch 53/100, Train Loss: 0.5701, Train Acc: 0.8016, Val Loss: 0.6312, Val Acc: 0.7902\n",
      "Epoch 54/100, Train Loss: 0.5680, Train Acc: 0.8035, Val Loss: 0.6118, Val Acc: 0.7940\n",
      "Epoch 55/100, Train Loss: 0.5588, Train Acc: 0.8058, Val Loss: 0.6085, Val Acc: 0.7924\n",
      "Epoch 56/100, Train Loss: 0.5604, Train Acc: 0.8072, Val Loss: 0.6050, Val Acc: 0.7912\n",
      "Epoch 57/100, Train Loss: 0.5550, Train Acc: 0.8056, Val Loss: 0.6146, Val Acc: 0.7910\n",
      "Epoch 58/100, Train Loss: 0.5510, Train Acc: 0.8093, Val Loss: 0.6377, Val Acc: 0.7858\n",
      "Epoch 59/100, Train Loss: 0.5510, Train Acc: 0.8068, Val Loss: 0.6086, Val Acc: 0.7958\n",
      "Epoch 60/100, Train Loss: 0.5497, Train Acc: 0.8082, Val Loss: 0.6186, Val Acc: 0.7938\n",
      "Epoch 61/100, Train Loss: 0.5469, Train Acc: 0.8116, Val Loss: 0.6221, Val Acc: 0.8022\n",
      "Epoch 62/100, Train Loss: 0.5452, Train Acc: 0.8107, Val Loss: 0.5904, Val Acc: 0.8012\n",
      "Epoch 63/100, Train Loss: 0.5459, Train Acc: 0.8102, Val Loss: 0.6028, Val Acc: 0.7974\n",
      "Epoch 64/100, Train Loss: 0.5404, Train Acc: 0.8116, Val Loss: 0.6103, Val Acc: 0.8010\n",
      "Epoch 65/100, Train Loss: 0.5347, Train Acc: 0.8153, Val Loss: 0.6074, Val Acc: 0.7928\n",
      "Epoch 66/100, Train Loss: 0.5304, Train Acc: 0.8152, Val Loss: 0.6407, Val Acc: 0.7880\n",
      "Epoch 67/100, Train Loss: 0.5313, Train Acc: 0.8150, Val Loss: 0.5970, Val Acc: 0.7964\n",
      "Epoch 68/100, Train Loss: 0.5312, Train Acc: 0.8157, Val Loss: 0.6162, Val Acc: 0.7938\n",
      "Epoch 69/100, Train Loss: 0.5253, Train Acc: 0.8167, Val Loss: 0.5982, Val Acc: 0.7958\n",
      "Epoch 70/100, Train Loss: 0.5264, Train Acc: 0.8185, Val Loss: 0.5971, Val Acc: 0.7974\n",
      "Epoch 71/100, Train Loss: 0.5321, Train Acc: 0.8142, Val Loss: 0.5875, Val Acc: 0.8046\n",
      "Epoch 72/100, Train Loss: 0.5219, Train Acc: 0.8186, Val Loss: 0.5832, Val Acc: 0.8014\n",
      "Epoch 73/100, Train Loss: 0.5174, Train Acc: 0.8189, Val Loss: 0.5977, Val Acc: 0.7988\n",
      "Epoch 74/100, Train Loss: 0.5148, Train Acc: 0.8221, Val Loss: 0.6216, Val Acc: 0.7944\n",
      "Epoch 75/100, Train Loss: 0.5114, Train Acc: 0.8230, Val Loss: 0.5883, Val Acc: 0.7986\n",
      "Epoch 76/100, Train Loss: 0.5162, Train Acc: 0.8211, Val Loss: 0.5911, Val Acc: 0.8004\n",
      "Epoch 77/100, Train Loss: 0.5100, Train Acc: 0.8230, Val Loss: 0.6142, Val Acc: 0.7952\n",
      "Epoch 78/100, Train Loss: 0.5050, Train Acc: 0.8246, Val Loss: 0.5978, Val Acc: 0.8022\n",
      "Epoch 79/100, Train Loss: 0.5109, Train Acc: 0.8237, Val Loss: 0.6132, Val Acc: 0.7970\n",
      "Epoch 80/100, Train Loss: 0.5077, Train Acc: 0.8232, Val Loss: 0.5749, Val Acc: 0.8046\n",
      "Epoch 81/100, Train Loss: 0.5063, Train Acc: 0.8250, Val Loss: 0.5823, Val Acc: 0.8024\n",
      "Epoch 82/100, Train Loss: 0.4983, Train Acc: 0.8265, Val Loss: 0.5955, Val Acc: 0.8000\n",
      "Epoch 83/100, Train Loss: 0.5016, Train Acc: 0.8254, Val Loss: 0.5698, Val Acc: 0.8100\n",
      "Epoch 84/100, Train Loss: 0.4969, Train Acc: 0.8245, Val Loss: 0.5959, Val Acc: 0.7980\n",
      "Epoch 85/100, Train Loss: 0.5007, Train Acc: 0.8267, Val Loss: 0.6123, Val Acc: 0.7932\n",
      "Epoch 86/100, Train Loss: 0.4978, Train Acc: 0.8284, Val Loss: 0.5855, Val Acc: 0.8054\n",
      "Epoch 87/100, Train Loss: 0.4905, Train Acc: 0.8280, Val Loss: 0.5494, Val Acc: 0.8048\n",
      "Epoch 88/100, Train Loss: 0.4893, Train Acc: 0.8317, Val Loss: 0.5930, Val Acc: 0.8028\n",
      "Epoch 89/100, Train Loss: 0.5003, Train Acc: 0.8263, Val Loss: 0.5794, Val Acc: 0.8072\n",
      "Epoch 90/100, Train Loss: 0.4901, Train Acc: 0.8301, Val Loss: 0.5799, Val Acc: 0.7988\n",
      "Epoch 91/100, Train Loss: 0.4906, Train Acc: 0.8303, Val Loss: 0.5818, Val Acc: 0.7976\n",
      "Epoch 92/100, Train Loss: 0.4806, Train Acc: 0.8332, Val Loss: 0.5774, Val Acc: 0.8146\n",
      "Epoch 93/100, Train Loss: 0.4895, Train Acc: 0.8283, Val Loss: 0.5820, Val Acc: 0.8022\n",
      "Epoch 94/100, Train Loss: 0.4785, Train Acc: 0.8337, Val Loss: 0.5725, Val Acc: 0.8044\n",
      "Epoch 95/100, Train Loss: 0.4835, Train Acc: 0.8320, Val Loss: 0.5683, Val Acc: 0.8088\n",
      "Epoch 96/100, Train Loss: 0.4801, Train Acc: 0.8334, Val Loss: 0.5693, Val Acc: 0.8158\n",
      "Epoch 97/100, Train Loss: 0.4800, Train Acc: 0.8346, Val Loss: 0.5808, Val Acc: 0.8154\n",
      "Epoch 98/100, Train Loss: 0.4807, Train Acc: 0.8336, Val Loss: 0.5848, Val Acc: 0.8016\n",
      "Epoch 99/100, Train Loss: 0.4744, Train Acc: 0.8344, Val Loss: 0.5621, Val Acc: 0.8158\n",
      "Epoch 100/100, Train Loss: 0.4749, Train Acc: 0.8351, Val Loss: 0.5696, Val Acc: 0.8078\n",
      "The final result of testing accuracy for CustomCNN after training for 100 epochs is 83.82%\n"
     ]
    }
   ],
   "source": [
    "# # Training loop with plotting data collection\n",
    "# torch.manual_seed(42)\n",
    "# torch.cuda.manual_seed(42)\n",
    "\n",
    "# num_epochs=100 \n",
    "# train_losses=[]\n",
    "# train_accuracies=[]\n",
    "# val_losses=[]\n",
    "# val_accuracies=[]\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss ,train_acc=train(trainloader, model0, criterion, optimizer)\n",
    "#     val_loss ,val_acc=validate(valloader, model0, criterion)\n",
    "\n",
    "#     train_losses.append(train_loss)\n",
    "#     train_accuracies.append(train_acc)\n",
    "#     val_losses.append(val_loss)\n",
    "#     val_accuracies.append(val_acc)\n",
    "\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "#           f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "#           f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# Made better function as run_experiment:\n",
    "def run_experiment(trainloader, testloader, model_class):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    num_epochs = 100\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(trainloader, model, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(valloader, model, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_acc = test(testloader, model)\n",
    "    print(f'The final result of testing accuracy for CustomCNN after training for {num_epochs} epochs is {test_acc * 100:.2f}%')\n",
    "\n",
    "print(\"Experiment with Initial Custom CNN:\")\n",
    "run_experiment(trainloader, testloader, CustomCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def imshow(img, ax):\n",
    "    ax.imshow(np.transpose((img / 2 + 0.5).numpy(), (1, 2, 0)))\n",
    "    ax.axis('off')\n",
    "\n",
    "def plot_examples(model, dataloader, classes, device):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(dataloader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    _, predicted = torch.max(model(images), 1)\n",
    "\n",
    "    correct_index = random.choice((predicted == labels).nonzero(as_tuple=True)[0]).item()\n",
    "    misclassified_index = random.choice((predicted != labels).nonzero(as_tuple=True)[0]).item()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    for idx, ax, title in zip([correct_index, misclassified_index], axes, [\"Correct\", \"Misclassified\"]):\n",
    "        imshow(images[idx].cpu(), ax)\n",
    "        ax.set_title(f\"{title}\\nTrue: {classes[labels[idx].item()]}\\nPred: {classes[predicted[idx].item()]}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# class names for CIFAR-10\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Call the function to plot classification examples\n",
    "plot_examples(model0, testloader, classes, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 -- Graduate Students\n",
    "\n",
    "For each of the following experiments run 10-20 epocs and observe the cost function. Determine the best setup based on the runs.\n",
    "\n",
    "**Did for 30 epochs to see the broader view, because at one point Increasing  Filter Size CNN gave me the best accuracy by 1-2% on 20 epochs while now with some modifications SmallFilterSizeCNN is giving me the best results.**\n",
    "\n",
    "1. Experiment with all convolutional layers having the same small filter size (e.g. 3x3)\n",
    "2. Experiment with all convolutional layers having the same large filter size (e.g. 15x15)\n",
    "3. Experiment with convolutional layers with increasing filter size (e.g. 3x3, 5x5, 7x7)\n",
    "4. Experiment with convolutional layers with decreasing filter size (e.g. 7x7, 5x5, 3x3)\n",
    "5. Experiment with L1 regularization, L2 regularization, dropout combination.\n",
    "6. Experiment with and without data augmentation.\n",
    "\n",
    "7. Generate a short report on based on the above experiment and upload it with your code . You can simply tabulate your results and provide a short analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Experiment with all convolutional layers having the same small filter size (e.g. 3x3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]           9,280\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 8, 8]         147,712\n",
      "         MaxPool2d-6            [-1, 256, 4, 4]               0\n",
      "            Linear-7                  [-1, 512]       2,097,664\n",
      "           Dropout-8                  [-1, 512]               0\n",
      "            Linear-9                  [-1, 128]          65,664\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,322,058\n",
      "Trainable params: 2,322,058\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 8.86\n",
      "Estimated Total Size (MB): 9.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class SmallFilterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallFilterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model1 = SmallFilterCNN().to(device)\n",
    "\n",
    "# model summary\n",
    "summary(model1,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with same Smaller Filter size:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 1.8945, Train Acc: 0.3257, Val Loss: 1.5601, Val Acc: 0.4254\n",
      "Epoch 2/30, Train Loss: 1.6169, Train Acc: 0.4527, Val Loss: 1.3732, Val Acc: 0.4990\n",
      "Epoch 3/30, Train Loss: 1.4687, Train Acc: 0.5188, Val Loss: 1.2977, Val Acc: 0.5230\n",
      "Epoch 4/30, Train Loss: 1.3709, Train Acc: 0.5621, Val Loss: 1.1017, Val Acc: 0.6110\n",
      "Epoch 5/30, Train Loss: 1.2906, Train Acc: 0.5980, Val Loss: 1.0726, Val Acc: 0.6254\n",
      "Epoch 6/30, Train Loss: 1.2334, Train Acc: 0.6258, Val Loss: 0.9841, Val Acc: 0.6608\n",
      "Epoch 7/30, Train Loss: 1.1950, Train Acc: 0.6409, Val Loss: 0.9443, Val Acc: 0.6672\n",
      "Epoch 8/30, Train Loss: 1.1587, Train Acc: 0.6569, Val Loss: 0.9175, Val Acc: 0.6858\n",
      "Epoch 9/30, Train Loss: 1.1316, Train Acc: 0.6695, Val Loss: 0.8846, Val Acc: 0.6930\n",
      "Epoch 10/30, Train Loss: 1.1087, Train Acc: 0.6819, Val Loss: 0.8946, Val Acc: 0.6940\n",
      "Epoch 11/30, Train Loss: 1.0835, Train Acc: 0.6922, Val Loss: 0.8372, Val Acc: 0.7120\n",
      "Epoch 12/30, Train Loss: 1.0700, Train Acc: 0.6979, Val Loss: 0.8489, Val Acc: 0.7034\n",
      "Epoch 13/30, Train Loss: 1.0597, Train Acc: 0.7025, Val Loss: 0.8284, Val Acc: 0.7116\n",
      "Epoch 14/30, Train Loss: 1.0359, Train Acc: 0.7141, Val Loss: 0.8149, Val Acc: 0.7248\n",
      "Epoch 15/30, Train Loss: 1.0277, Train Acc: 0.7193, Val Loss: 0.7773, Val Acc: 0.7296\n",
      "Epoch 16/30, Train Loss: 1.0196, Train Acc: 0.7221, Val Loss: 0.7705, Val Acc: 0.7310\n",
      "Epoch 17/30, Train Loss: 1.0100, Train Acc: 0.7266, Val Loss: 0.7873, Val Acc: 0.7296\n",
      "Epoch 18/30, Train Loss: 1.0066, Train Acc: 0.7281, Val Loss: 0.7620, Val Acc: 0.7274\n",
      "Epoch 19/30, Train Loss: 1.0010, Train Acc: 0.7332, Val Loss: 0.7964, Val Acc: 0.7262\n",
      "Epoch 20/30, Train Loss: 0.9845, Train Acc: 0.7407, Val Loss: 0.7439, Val Acc: 0.7458\n",
      "Epoch 21/30, Train Loss: 0.9816, Train Acc: 0.7412, Val Loss: 0.7335, Val Acc: 0.7432\n",
      "Epoch 22/30, Train Loss: 0.9794, Train Acc: 0.7445, Val Loss: 0.7594, Val Acc: 0.7450\n",
      "Epoch 23/30, Train Loss: 0.9720, Train Acc: 0.7463, Val Loss: 0.7365, Val Acc: 0.7436\n",
      "Epoch 24/30, Train Loss: 0.9713, Train Acc: 0.7476, Val Loss: 0.7541, Val Acc: 0.7414\n",
      "Epoch 25/30, Train Loss: 0.9582, Train Acc: 0.7532, Val Loss: 0.7277, Val Acc: 0.7464\n",
      "Epoch 26/30, Train Loss: 0.9543, Train Acc: 0.7563, Val Loss: 0.7241, Val Acc: 0.7506\n",
      "Epoch 27/30, Train Loss: 0.9519, Train Acc: 0.7574, Val Loss: 0.6884, Val Acc: 0.7562\n",
      "Epoch 28/30, Train Loss: 0.9452, Train Acc: 0.7632, Val Loss: 0.6936, Val Acc: 0.7632\n",
      "Epoch 29/30, Train Loss: 0.9435, Train Acc: 0.7614, Val Loss: 0.7110, Val Acc: 0.7618\n",
      "Epoch 30/30, Train Loss: 0.9380, Train Acc: 0.7636, Val Loss: 0.6898, Val Acc: 0.7598\n",
      "The final result of testing accuracy for SmallFilterCNN model after training for 30 epochs is 80.55%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(trainloader, testloader, model_class):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    num_epochs = 30\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(trainloader, model, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(valloader, model, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_acc = test(testloader, model)\n",
    "    print(f'The final result of testing accuracy for SmallFilterCNN model after training for {num_epochs} epochs is {test_acc * 100:.2f}%')\n",
    "\n",
    "print(\"Experiment with same Smaller Filter size:\")\n",
    "run_experiment(trainloader, testloader, SmallFilterCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Experiment with all convolutional layers having the same large filter size (e.g. 15x15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]          10,816\n",
      "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]         230,464\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 8, 8]       3,686,656\n",
      "         MaxPool2d-6            [-1, 256, 4, 4]               0\n",
      "            Linear-7                  [-1, 512]       2,097,664\n",
      "           Dropout-8                  [-1, 512]               0\n",
      "            Linear-9                  [-1, 128]          65,664\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 6,092,554\n",
      "Trainable params: 6,092,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 23.24\n",
      "Estimated Total Size (MB): 23.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class LargeFilterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargeFilterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=15, padding=7)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=15, padding=7)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=15, padding=7)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model2 = LargeFilterCNN().to(device)\n",
    "summary(model2,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with same Large filter size:\n",
      "Epoch 1/30, Train Loss: 2.0706, Train Acc: 0.2412, Val Loss: 1.8866, Val Acc: 0.3014\n",
      "Epoch 2/30, Train Loss: 1.8458, Train Acc: 0.3491, Val Loss: 1.6409, Val Acc: 0.4000\n",
      "Epoch 3/30, Train Loss: 1.7358, Train Acc: 0.4122, Val Loss: 1.5533, Val Acc: 0.4460\n",
      "Epoch 4/30, Train Loss: 1.6623, Train Acc: 0.4481, Val Loss: 1.5330, Val Acc: 0.4614\n",
      "Epoch 5/30, Train Loss: 1.6162, Train Acc: 0.4688, Val Loss: 1.5127, Val Acc: 0.4620\n",
      "Epoch 6/30, Train Loss: 1.5802, Train Acc: 0.4885, Val Loss: 1.4163, Val Acc: 0.4924\n",
      "Epoch 7/30, Train Loss: 1.5453, Train Acc: 0.5011, Val Loss: 1.3872, Val Acc: 0.5152\n",
      "Epoch 8/30, Train Loss: 1.5249, Train Acc: 0.5120, Val Loss: 1.3453, Val Acc: 0.5364\n",
      "Epoch 9/30, Train Loss: 1.5048, Train Acc: 0.5216, Val Loss: 1.3259, Val Acc: 0.5318\n",
      "Epoch 10/30, Train Loss: 1.4970, Train Acc: 0.5265, Val Loss: 1.2910, Val Acc: 0.5378\n",
      "Epoch 11/30, Train Loss: 1.4780, Train Acc: 0.5379, Val Loss: 1.2980, Val Acc: 0.5430\n",
      "Epoch 12/30, Train Loss: 1.4638, Train Acc: 0.5409, Val Loss: 1.2810, Val Acc: 0.5576\n",
      "Epoch 13/30, Train Loss: 1.4528, Train Acc: 0.5495, Val Loss: 1.2879, Val Acc: 0.5480\n",
      "Epoch 14/30, Train Loss: 1.4367, Train Acc: 0.5568, Val Loss: 1.2700, Val Acc: 0.5600\n",
      "Epoch 15/30, Train Loss: 1.4247, Train Acc: 0.5681, Val Loss: 1.2385, Val Acc: 0.5712\n",
      "Epoch 16/30, Train Loss: 1.4137, Train Acc: 0.5721, Val Loss: 1.2456, Val Acc: 0.5658\n",
      "Epoch 17/30, Train Loss: 1.4071, Train Acc: 0.5795, Val Loss: 1.2016, Val Acc: 0.5822\n",
      "Epoch 18/30, Train Loss: 1.4002, Train Acc: 0.5848, Val Loss: 1.1728, Val Acc: 0.5898\n",
      "Epoch 19/30, Train Loss: 1.3856, Train Acc: 0.5879, Val Loss: 1.1929, Val Acc: 0.5886\n",
      "Epoch 20/30, Train Loss: 1.3779, Train Acc: 0.5950, Val Loss: 1.1772, Val Acc: 0.5916\n",
      "Epoch 21/30, Train Loss: 1.3642, Train Acc: 0.5989, Val Loss: 1.1681, Val Acc: 0.5996\n",
      "Epoch 22/30, Train Loss: 1.3593, Train Acc: 0.6041, Val Loss: 1.1207, Val Acc: 0.6156\n",
      "Epoch 23/30, Train Loss: 1.3504, Train Acc: 0.6107, Val Loss: 1.1908, Val Acc: 0.5866\n",
      "Epoch 24/30, Train Loss: 1.3391, Train Acc: 0.6093, Val Loss: 1.1154, Val Acc: 0.6042\n",
      "Epoch 25/30, Train Loss: 1.3437, Train Acc: 0.6135, Val Loss: 1.1021, Val Acc: 0.6142\n",
      "Epoch 26/30, Train Loss: 1.3276, Train Acc: 0.6174, Val Loss: 1.1126, Val Acc: 0.6150\n",
      "Epoch 27/30, Train Loss: 1.3276, Train Acc: 0.6187, Val Loss: 1.0845, Val Acc: 0.6212\n",
      "Epoch 28/30, Train Loss: 1.3185, Train Acc: 0.6220, Val Loss: 1.0905, Val Acc: 0.6260\n",
      "Epoch 29/30, Train Loss: 1.3155, Train Acc: 0.6252, Val Loss: 1.0746, Val Acc: 0.6298\n",
      "Epoch 30/30, Train Loss: 1.3068, Train Acc: 0.6288, Val Loss: 1.0662, Val Acc: 0.6276\n",
      "The final result of testing accuracy for LargeFilterCNN model after training for 30 epochs is 65.49%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(trainloader, testloader, model_class):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    num_epochs = 30\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(trainloader, model, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(valloader, model, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_acc = test(testloader, model)\n",
    "    print(f'The final result of testing accuracy for LargeFilterCNN model after training for {num_epochs} epochs is {test_acc * 100:.2f}%')\n",
    "\n",
    "print(\"Experiment with same Large filter size:\")\n",
    "run_experiment(trainloader, testloader, LargeFilterCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Experiment with convolutional layers with increasing filter size (e.g. 3x3, 5x5, 7x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]          25,664\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 8, 8]         803,072\n",
      "         MaxPool2d-6            [-1, 256, 4, 4]               0\n",
      "            Linear-7                  [-1, 512]       2,097,664\n",
      "           Dropout-8                  [-1, 512]               0\n",
      "            Linear-9                  [-1, 128]          65,664\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,993,802\n",
      "Trainable params: 2,993,802\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 11.42\n",
      "Estimated Total Size (MB): 11.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class IncreasingFilterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IncreasingFilterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=7, padding=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256*4*4,512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,256*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model3 = IncreasingFilterCNN().to(device)\n",
    "summary(model3,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Increasing filter size:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 1.9254, Train Acc: 0.2930, Val Loss: 1.6431, Val Acc: 0.3902\n",
      "Epoch 2/30, Train Loss: 1.5660, Train Acc: 0.4597, Val Loss: 1.3500, Val Acc: 0.5184\n",
      "Epoch 3/30, Train Loss: 1.4191, Train Acc: 0.5277, Val Loss: 1.2672, Val Acc: 0.5510\n",
      "Epoch 4/30, Train Loss: 1.3309, Train Acc: 0.5669, Val Loss: 1.1925, Val Acc: 0.5818\n",
      "Epoch 5/30, Train Loss: 1.2736, Train Acc: 0.5950, Val Loss: 1.0885, Val Acc: 0.6154\n",
      "Epoch 6/30, Train Loss: 1.2224, Train Acc: 0.6186, Val Loss: 1.1089, Val Acc: 0.6220\n",
      "Epoch 7/30, Train Loss: 1.1702, Train Acc: 0.6395, Val Loss: 0.9846, Val Acc: 0.6584\n",
      "Epoch 8/30, Train Loss: 1.1414, Train Acc: 0.6518, Val Loss: 0.9323, Val Acc: 0.6758\n",
      "Epoch 9/30, Train Loss: 1.1151, Train Acc: 0.6664, Val Loss: 0.9271, Val Acc: 0.6778\n",
      "Epoch 10/30, Train Loss: 1.0928, Train Acc: 0.6782, Val Loss: 0.8955, Val Acc: 0.6932\n",
      "Epoch 11/30, Train Loss: 1.0731, Train Acc: 0.6852, Val Loss: 0.9366, Val Acc: 0.6708\n",
      "Epoch 12/30, Train Loss: 1.0483, Train Acc: 0.6950, Val Loss: 0.8957, Val Acc: 0.6910\n",
      "Epoch 13/30, Train Loss: 1.0302, Train Acc: 0.7016, Val Loss: 0.8875, Val Acc: 0.6968\n",
      "Epoch 14/30, Train Loss: 1.0195, Train Acc: 0.7070, Val Loss: 0.8493, Val Acc: 0.7082\n",
      "Epoch 15/30, Train Loss: 1.0054, Train Acc: 0.7163, Val Loss: 0.8199, Val Acc: 0.7178\n",
      "Epoch 16/30, Train Loss: 0.9978, Train Acc: 0.7183, Val Loss: 0.8558, Val Acc: 0.7156\n",
      "Epoch 17/30, Train Loss: 0.9879, Train Acc: 0.7225, Val Loss: 0.8335, Val Acc: 0.7208\n",
      "Epoch 18/30, Train Loss: 0.9845, Train Acc: 0.7231, Val Loss: 0.8224, Val Acc: 0.7188\n",
      "Epoch 19/30, Train Loss: 0.9722, Train Acc: 0.7331, Val Loss: 0.8122, Val Acc: 0.7274\n",
      "Epoch 20/30, Train Loss: 0.9640, Train Acc: 0.7369, Val Loss: 0.7831, Val Acc: 0.7368\n",
      "Epoch 21/30, Train Loss: 0.9613, Train Acc: 0.7379, Val Loss: 0.7820, Val Acc: 0.7348\n",
      "Epoch 22/30, Train Loss: 0.9538, Train Acc: 0.7435, Val Loss: 0.7946, Val Acc: 0.7344\n",
      "Epoch 23/30, Train Loss: 0.9443, Train Acc: 0.7428, Val Loss: 0.8012, Val Acc: 0.7306\n",
      "Epoch 24/30, Train Loss: 0.9294, Train Acc: 0.7493, Val Loss: 0.7643, Val Acc: 0.7418\n",
      "Epoch 25/30, Train Loss: 0.9327, Train Acc: 0.7471, Val Loss: 0.7816, Val Acc: 0.7354\n",
      "Epoch 26/30, Train Loss: 0.9274, Train Acc: 0.7533, Val Loss: 0.7541, Val Acc: 0.7482\n",
      "Epoch 27/30, Train Loss: 0.9288, Train Acc: 0.7532, Val Loss: 0.7745, Val Acc: 0.7346\n",
      "Epoch 28/30, Train Loss: 0.9296, Train Acc: 0.7537, Val Loss: 0.7632, Val Acc: 0.7564\n",
      "Epoch 29/30, Train Loss: 0.9320, Train Acc: 0.7575, Val Loss: 0.7511, Val Acc: 0.7488\n",
      "Epoch 30/30, Train Loss: 0.9128, Train Acc: 0.7587, Val Loss: 0.7484, Val Acc: 0.7452\n",
      "The final result of testing accuracy for IncreasingFilterCNN model after training for 30 epochs is 77.41%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(trainloader, testloader, model_class):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    num_epochs = 30\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(trainloader, model, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(valloader, model, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_acc = test(testloader, model)\n",
    "    print(f'The final result of testing accuracy for IncreasingFilterCNN model after training for {num_epochs} epochs is {test_acc * 100:.2f}%')\n",
    "\n",
    "print(\"Experiment with Increasing filter size:\")\n",
    "run_experiment(trainloader, testloader, IncreasingFilterCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Experiment with convolutional layers with decreasing filter size (e.g. 7x7, 5x5, 3x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]           2,368\n",
      "         MaxPool2d-2           [-1, 16, 16, 16]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]          25,664\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 256, 8, 8]         147,712\n",
      "         MaxPool2d-6            [-1, 256, 4, 4]               0\n",
      "            Linear-7                  [-1, 512]       2,097,664\n",
      "           Dropout-8                  [-1, 512]               0\n",
      "            Linear-9                  [-1, 128]          65,664\n",
      "           Linear-10                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,340,362\n",
      "Trainable params: 2,340,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 8.93\n",
      "Estimated Total Size (MB): 9.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class DecreasingFilterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecreasingFilterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model4 = DecreasingFilterCNN().to(device)\n",
    "summary(model4,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Increasing filter size:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 1.9483, Train Acc: 0.3123, Val Loss: 1.6519, Val Acc: 0.4026\n",
      "Epoch 2/30, Train Loss: 1.6495, Train Acc: 0.4448, Val Loss: 1.4066, Val Acc: 0.4998\n",
      "Epoch 3/30, Train Loss: 1.5039, Train Acc: 0.5098, Val Loss: 1.2706, Val Acc: 0.5502\n",
      "Epoch 4/30, Train Loss: 1.4109, Train Acc: 0.5573, Val Loss: 1.1825, Val Acc: 0.5928\n",
      "Epoch 5/30, Train Loss: 1.3347, Train Acc: 0.5923, Val Loss: 1.1459, Val Acc: 0.6046\n",
      "Epoch 6/30, Train Loss: 1.2860, Train Acc: 0.6164, Val Loss: 1.0324, Val Acc: 0.6508\n",
      "Epoch 7/30, Train Loss: 1.2434, Train Acc: 0.6349, Val Loss: 1.0060, Val Acc: 0.6510\n",
      "Epoch 8/30, Train Loss: 1.2108, Train Acc: 0.6501, Val Loss: 1.0133, Val Acc: 0.6476\n",
      "Epoch 9/30, Train Loss: 1.1843, Train Acc: 0.6638, Val Loss: 0.9610, Val Acc: 0.6684\n",
      "Epoch 10/30, Train Loss: 1.1627, Train Acc: 0.6705, Val Loss: 0.8947, Val Acc: 0.6892\n",
      "Epoch 11/30, Train Loss: 1.1447, Train Acc: 0.6789, Val Loss: 0.9026, Val Acc: 0.6838\n",
      "Epoch 12/30, Train Loss: 1.1236, Train Acc: 0.6894, Val Loss: 0.8951, Val Acc: 0.6908\n",
      "Epoch 13/30, Train Loss: 1.1128, Train Acc: 0.6963, Val Loss: 0.8528, Val Acc: 0.7102\n",
      "Epoch 14/30, Train Loss: 1.1005, Train Acc: 0.7028, Val Loss: 0.8616, Val Acc: 0.6990\n",
      "Epoch 15/30, Train Loss: 1.0971, Train Acc: 0.7060, Val Loss: 0.8396, Val Acc: 0.7074\n",
      "Epoch 16/30, Train Loss: 1.0877, Train Acc: 0.7124, Val Loss: 0.8523, Val Acc: 0.7012\n",
      "Epoch 17/30, Train Loss: 1.0812, Train Acc: 0.7159, Val Loss: 0.8128, Val Acc: 0.7292\n",
      "Epoch 18/30, Train Loss: 1.0794, Train Acc: 0.7157, Val Loss: 0.8012, Val Acc: 0.7266\n",
      "Epoch 19/30, Train Loss: 1.0695, Train Acc: 0.7226, Val Loss: 0.7846, Val Acc: 0.7316\n",
      "Epoch 20/30, Train Loss: 1.0467, Train Acc: 0.7304, Val Loss: 0.7715, Val Acc: 0.7370\n",
      "Epoch 21/30, Train Loss: 1.0434, Train Acc: 0.7326, Val Loss: 0.8264, Val Acc: 0.7108\n",
      "Epoch 22/30, Train Loss: 1.0424, Train Acc: 0.7327, Val Loss: 0.7968, Val Acc: 0.7284\n",
      "Epoch 23/30, Train Loss: 1.0379, Train Acc: 0.7361, Val Loss: 0.7256, Val Acc: 0.7498\n",
      "Epoch 24/30, Train Loss: 1.0380, Train Acc: 0.7397, Val Loss: 0.7445, Val Acc: 0.7376\n",
      "Epoch 25/30, Train Loss: 1.0146, Train Acc: 0.7435, Val Loss: 0.7544, Val Acc: 0.7422\n",
      "Epoch 26/30, Train Loss: 1.0271, Train Acc: 0.7459, Val Loss: 0.7552, Val Acc: 0.7390\n",
      "Epoch 27/30, Train Loss: 1.0166, Train Acc: 0.7473, Val Loss: 0.7718, Val Acc: 0.7398\n",
      "Epoch 28/30, Train Loss: 1.0182, Train Acc: 0.7489, Val Loss: 0.7720, Val Acc: 0.7346\n",
      "Epoch 29/30, Train Loss: 1.0122, Train Acc: 0.7526, Val Loss: 0.7102, Val Acc: 0.7530\n",
      "Epoch 30/30, Train Loss: 1.0097, Train Acc: 0.7547, Val Loss: 0.7207, Val Acc: 0.7518\n",
      "The final result of testing accuracy for DecreasingFilterCNN model after training for 30 epochs is 78.81%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(trainloader, testloader, model_class):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    num_epochs = 30\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(trainloader, model, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(valloader, model, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_acc = test(testloader, model)\n",
    "    print(f'The final result of testing accuracy for DecreasingFilterCNN model after training for {num_epochs} epochs is {test_acc * 100:.2f}%')\n",
    "\n",
    "print(\"Experiment with Increasing filter size:\")\n",
    "run_experiment(trainloader, testloader, DecreasingFilterCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reporting:\n",
    "\n",
    "1. Small Filters (3x3): Showed steady convergence with good generalization, achieving a highest testing accuracy of 80.55%.\n",
    "2. Large Filters (15x15): Converge more slowly and achieve lower performance, with a test accuracy of 65.49%, likely due to overfitting.\n",
    "3. Increasing Filter Sizes (3x3, 5x5, 7x7): Shows good convergence with consistent decrease in losses. Achieved the test accuracy of 77.41%, effectively balancing detail capture and broader pattern recognition.\n",
    "4. Decreasing Filter Sizes (7x7, 5x5, 3x3): Performed well with a test accuracy of 78.81%, but slightly more effective than increasing sizes.\n",
    "\n",
    "Conclusion: Small filter sizes provide the best balance and performance, making them a strong choice for capturing both fine details and broader patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Experiment with L1 regularization, L2 regularization, dropout combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBESTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomBESTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256*4*4, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model5 = CustomBESTCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model5.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Training function with L1 regularization\n",
    "def train(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    l1_lambda = 1e-5\n",
    "\n",
    "    for X, Y in dataloader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, Y)\n",
    "\n",
    "        # Add L1 regularization\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss += l1_lambda * l1_norm\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += (pred.argmax(dim=1) == Y).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / len(dataloader.dataset)\n",
    "\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with L1, L2 and Dropout filter size:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 1.9277, Train Acc: 0.2923, Val Loss: 1.6458, Val Acc: 0.3898\n",
      "Epoch 2/20, Train Loss: 1.5848, Train Acc: 0.4496, Val Loss: 1.3851, Val Acc: 0.4994\n",
      "Epoch 3/20, Train Loss: 1.4328, Train Acc: 0.5190, Val Loss: 1.2781, Val Acc: 0.5374\n",
      "Epoch 4/20, Train Loss: 1.3477, Train Acc: 0.5623, Val Loss: 1.2221, Val Acc: 0.5658\n",
      "Epoch 5/20, Train Loss: 1.2760, Train Acc: 0.5895, Val Loss: 1.0982, Val Acc: 0.6124\n",
      "Epoch 6/20, Train Loss: 1.2267, Train Acc: 0.6156, Val Loss: 1.0743, Val Acc: 0.6256\n",
      "Epoch 7/20, Train Loss: 1.1721, Train Acc: 0.6367, Val Loss: 1.0291, Val Acc: 0.6480\n",
      "Epoch 8/20, Train Loss: 1.1379, Train Acc: 0.6522, Val Loss: 0.9284, Val Acc: 0.6802\n",
      "Epoch 9/20, Train Loss: 1.1162, Train Acc: 0.6661, Val Loss: 0.9246, Val Acc: 0.6844\n",
      "Epoch 10/20, Train Loss: 1.0967, Train Acc: 0.6723, Val Loss: 0.9232, Val Acc: 0.6794\n",
      "Epoch 11/20, Train Loss: 1.0714, Train Acc: 0.6859, Val Loss: 0.9445, Val Acc: 0.6842\n",
      "Epoch 12/20, Train Loss: 1.0471, Train Acc: 0.6932, Val Loss: 0.8797, Val Acc: 0.7016\n",
      "Epoch 13/20, Train Loss: 1.0296, Train Acc: 0.7011, Val Loss: 0.8884, Val Acc: 0.6954\n",
      "Epoch 14/20, Train Loss: 1.0240, Train Acc: 0.7054, Val Loss: 0.8604, Val Acc: 0.7098\n",
      "Epoch 15/20, Train Loss: 1.0052, Train Acc: 0.7155, Val Loss: 0.8662, Val Acc: 0.7044\n",
      "Epoch 16/20, Train Loss: 1.0084, Train Acc: 0.7153, Val Loss: 0.8998, Val Acc: 0.6936\n",
      "Epoch 17/20, Train Loss: 0.9889, Train Acc: 0.7226, Val Loss: 0.8190, Val Acc: 0.7212\n",
      "Epoch 18/20, Train Loss: 0.9839, Train Acc: 0.7240, Val Loss: 0.8228, Val Acc: 0.7244\n",
      "Epoch 19/20, Train Loss: 0.9745, Train Acc: 0.7280, Val Loss: 0.8254, Val Acc: 0.7242\n",
      "Epoch 20/20, Train Loss: 0.9631, Train Acc: 0.7357, Val Loss: 0.7993, Val Acc: 0.7342\n",
      "The final result of testing accuracy with L1/L2 and dropout regularization with CustomBestCNN after training for 20 epochs is 77.17%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(trainloader, testloader, model_class):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    model = model_class().to(device)  # Instantiate the provided model class\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    num_epochs = 20\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(trainloader, model, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(valloader, model, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_acc = test(testloader, model)\n",
    "    print(f'The final result of testing accuracy with L1/L2 and dropout regularization with CustomBestCNN after training for {num_epochs} epochs is {test_acc * 100:.2f}%')\n",
    "\n",
    "print(\"Experiment with L1, L2 and Dropout filter size:\")\n",
    "run_experiment(trainloader, testloader, CustomBESTCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Experimentation with and without data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# defining data augmentation transformations for training\n",
    "transform_train_augmented = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Loading datasets with data augmentation\n",
    "trainset_augmented = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_augmented)\n",
    "trainloader_augmented = DataLoader(trainset_augmented, batch_size=128, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transformations for training without augmentation\n",
    "transform_train_no_aug = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Loading datasets without data augmentation\n",
    "trainset_no_aug = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_no_aug)\n",
    "trainloader_no_aug = DataLoader(trainset_no_aug, batch_size=128, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Data Augmentation:\n",
      "Epoch 1/20, Train Loss: 1.8797, Train Acc: 0.3352, Val Loss: 1.5786, Val Acc: 0.4350\n",
      "Epoch 2/20, Train Loss: 1.5874, Train Acc: 0.4665, Val Loss: 1.3201, Val Acc: 0.5276\n",
      "Epoch 3/20, Train Loss: 1.4227, Train Acc: 0.5360, Val Loss: 1.2074, Val Acc: 0.5708\n",
      "Epoch 4/20, Train Loss: 1.3237, Train Acc: 0.5792, Val Loss: 1.1096, Val Acc: 0.6040\n",
      "Epoch 5/20, Train Loss: 1.2573, Train Acc: 0.6091, Val Loss: 0.9912, Val Acc: 0.6548\n",
      "Epoch 6/20, Train Loss: 1.2090, Train Acc: 0.6304, Val Loss: 0.9463, Val Acc: 0.6746\n",
      "Epoch 7/20, Train Loss: 1.1704, Train Acc: 0.6514, Val Loss: 0.8892, Val Acc: 0.6944\n",
      "Epoch 8/20, Train Loss: 1.1308, Train Acc: 0.6682, Val Loss: 0.8683, Val Acc: 0.6994\n",
      "Epoch 9/20, Train Loss: 1.1127, Train Acc: 0.6764, Val Loss: 0.8249, Val Acc: 0.7180\n",
      "Epoch 10/20, Train Loss: 1.0899, Train Acc: 0.6866, Val Loss: 0.8200, Val Acc: 0.7200\n",
      "Epoch 11/20, Train Loss: 1.0657, Train Acc: 0.6949, Val Loss: 0.8087, Val Acc: 0.7260\n",
      "Epoch 12/20, Train Loss: 1.0538, Train Acc: 0.7044, Val Loss: 0.7657, Val Acc: 0.7296\n",
      "Epoch 13/20, Train Loss: 1.0407, Train Acc: 0.7095, Val Loss: 0.7478, Val Acc: 0.7468\n",
      "Epoch 14/20, Train Loss: 1.0194, Train Acc: 0.7173, Val Loss: 0.7573, Val Acc: 0.7402\n",
      "Epoch 15/20, Train Loss: 1.0178, Train Acc: 0.7213, Val Loss: 0.7392, Val Acc: 0.7514\n",
      "Epoch 16/20, Train Loss: 1.0069, Train Acc: 0.7270, Val Loss: 0.7034, Val Acc: 0.7634\n",
      "Epoch 17/20, Train Loss: 0.9981, Train Acc: 0.7308, Val Loss: 0.7179, Val Acc: 0.7532\n",
      "Epoch 18/20, Train Loss: 0.9915, Train Acc: 0.7325, Val Loss: 0.7002, Val Acc: 0.7558\n",
      "Epoch 19/20, Train Loss: 0.9864, Train Acc: 0.7363, Val Loss: 0.6833, Val Acc: 0.7598\n",
      "Epoch 20/20, Train Loss: 0.9741, Train Acc: 0.7387, Val Loss: 0.6551, Val Acc: 0.7760\n",
      "The final result of testing accuracy after training for 20 epochs is 78.53%\n",
      "\n",
      "Training without Data Augmentation:\n",
      "Epoch 1/20, Train Loss: 1.6847, Train Acc: 0.4223, Val Loss: 2.0405, Val Acc: 0.3344\n",
      "Epoch 2/20, Train Loss: 1.3314, Train Acc: 0.5835, Val Loss: 1.7020, Val Acc: 0.4384\n",
      "Epoch 3/20, Train Loss: 1.1577, Train Acc: 0.6615, Val Loss: 1.6937, Val Acc: 0.4556\n",
      "Epoch 4/20, Train Loss: 1.0489, Train Acc: 0.7110, Val Loss: 1.5025, Val Acc: 0.5014\n",
      "Epoch 5/20, Train Loss: 0.9691, Train Acc: 0.7433, Val Loss: 1.5419, Val Acc: 0.5038\n",
      "Epoch 6/20, Train Loss: 0.8945, Train Acc: 0.7747, Val Loss: 1.5795, Val Acc: 0.5050\n",
      "Epoch 7/20, Train Loss: 0.8398, Train Acc: 0.7995, Val Loss: 1.5806, Val Acc: 0.5264\n",
      "Epoch 8/20, Train Loss: 0.7976, Train Acc: 0.8206, Val Loss: 1.6364, Val Acc: 0.5278\n",
      "Epoch 9/20, Train Loss: 0.7606, Train Acc: 0.8384, Val Loss: 1.6677, Val Acc: 0.5350\n",
      "Epoch 10/20, Train Loss: 0.7201, Train Acc: 0.8573, Val Loss: 1.6594, Val Acc: 0.5304\n",
      "Epoch 11/20, Train Loss: 0.6909, Train Acc: 0.8722, Val Loss: 2.0511, Val Acc: 0.5036\n",
      "Epoch 12/20, Train Loss: 0.6628, Train Acc: 0.8855, Val Loss: 1.8092, Val Acc: 0.5440\n",
      "Epoch 13/20, Train Loss: 0.6377, Train Acc: 0.8987, Val Loss: 2.3523, Val Acc: 0.5230\n",
      "Epoch 14/20, Train Loss: 0.6264, Train Acc: 0.9063, Val Loss: 2.0800, Val Acc: 0.5276\n",
      "Epoch 15/20, Train Loss: 0.6150, Train Acc: 0.9151, Val Loss: 2.1981, Val Acc: 0.5176\n",
      "Epoch 16/20, Train Loss: 0.5991, Train Acc: 0.9232, Val Loss: 2.2604, Val Acc: 0.5078\n",
      "Epoch 17/20, Train Loss: 0.5942, Train Acc: 0.9269, Val Loss: 2.4128, Val Acc: 0.5168\n",
      "Epoch 18/20, Train Loss: 0.5837, Train Acc: 0.9329, Val Loss: 2.4418, Val Acc: 0.5130\n",
      "Epoch 19/20, Train Loss: 0.5725, Train Acc: 0.9383, Val Loss: 2.4588, Val Acc: 0.5336\n",
      "Epoch 20/20, Train Loss: 0.5609, Train Acc: 0.9428, Val Loss: 2.6709, Val Acc: 0.5252\n",
      "The final result of testing accuracy after training for 20 epochs is 76.86%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(trainloader, testloader):\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    \n",
    "    model = CustomBESTCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "    num_epochs = 20\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(trainloader, model, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(valloader, model, criterion)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    test_acc = test(testloader, model)\n",
    "    print(f'The final result of testing accuracy after training for {num_epochs} epochs is {test_acc * 100:.2f}%')\n",
    "\n",
    "# with data augmentation\n",
    "print(\"Training with Data Augmentation:\")\n",
    "run_experiment(trainloader_augmented, testloader)\n",
    "\n",
    "# without data augmentation\n",
    "print(\"\\nTraining without Data Augmentation:\")\n",
    "run_experiment(trainloader_no_aug, testloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_98726 th {\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_98726_row0_col0, #T_98726_row0_col1, #T_98726_row0_col2, #T_98726_row1_col0, #T_98726_row1_col1, #T_98726_row1_col2, #T_98726_row2_col0, #T_98726_row2_col1, #T_98726_row2_col2, #T_98726_row3_col0, #T_98726_row3_col1, #T_98726_row3_col2, #T_98726_row4_col0, #T_98726_row4_col1, #T_98726_row4_col2, #T_98726_row5_col0, #T_98726_row5_col1, #T_98726_row5_col2, #T_98726_row6_col0, #T_98726_row6_col1, #T_98726_row6_col2, #T_98726_row7_col0, #T_98726_row7_col1, #T_98726_row7_col2 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_98726\">\n",
       "  <caption>Experimental Results Summary</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_98726_level0_col0\" class=\"col_heading level0 col0\" >Experiment</th>\n",
       "      <th id=\"T_98726_level0_col1\" class=\"col_heading level0 col1\" >Validation Accuracy (%)</th>\n",
       "      <th id=\"T_98726_level0_col2\" class=\"col_heading level0 col2\" >Testing Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_98726_row0_col0\" class=\"data row0 col0\" >Initial CustomCNN (100 epochs)</td>\n",
       "      <td id=\"T_98726_row0_col1\" class=\"data row0 col1\" >81.94%</td>\n",
       "      <td id=\"T_98726_row0_col2\" class=\"data row0 col2\" >83.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_98726_row1_col0\" class=\"data row1 col0\" >Small Filters (3x3)</td>\n",
       "      <td id=\"T_98726_row1_col1\" class=\"data row1 col1\" >74.90%</td>\n",
       "      <td id=\"T_98726_row1_col2\" class=\"data row1 col2\" >80.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_98726_row2_col0\" class=\"data row2 col0\" >Large Filters (15x15)</td>\n",
       "      <td id=\"T_98726_row2_col1\" class=\"data row2 col1\" >56.18%</td>\n",
       "      <td id=\"T_98726_row2_col2\" class=\"data row2 col2\" >65.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_98726_row3_col0\" class=\"data row3 col0\" >Increasing Filter Sizes (3x3, 5x5, 7x7)</td>\n",
       "      <td id=\"T_98726_row3_col1\" class=\"data row3 col1\" >73.60%</td>\n",
       "      <td id=\"T_98726_row3_col2\" class=\"data row3 col2\" >77.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_98726_row4_col0\" class=\"data row4 col0\" >Decreasing Filter Sizes (7x7, 5x5, 3x3)</td>\n",
       "      <td id=\"T_98726_row4_col1\" class=\"data row4 col1\" >72.94%</td>\n",
       "      <td id=\"T_98726_row4_col2\" class=\"data row4 col2\" >78.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_98726_row5_col0\" class=\"data row5 col0\" >L1/L2 Regularization with Dropout</td>\n",
       "      <td id=\"T_98726_row5_col1\" class=\"data row5 col1\" >73.42%</td>\n",
       "      <td id=\"T_98726_row5_col2\" class=\"data row5 col2\" >77.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_98726_row6_col0\" class=\"data row6 col0\" >With Data Augmentation</td>\n",
       "      <td id=\"T_98726_row6_col1\" class=\"data row6 col1\" >77.60%</td>\n",
       "      <td id=\"T_98726_row6_col2\" class=\"data row6 col2\" >78.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98726_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_98726_row7_col0\" class=\"data row7 col0\" >Without Data Augmentation</td>\n",
       "      <td id=\"T_98726_row7_col1\" class=\"data row7 col1\" >52.52%</td>\n",
       "      <td id=\"T_98726_row7_col2\" class=\"data row7 col2\" >76.86%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2d408612e0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# summarizing the experimental results in the table\n",
    "results_data = {\n",
    "    'Experiment': [\n",
    "        'Initial CustomCNN (100 epochs)',\n",
    "        'Small Filters (3x3)',\n",
    "        'Large Filters (15x15)',\n",
    "        'Increasing Filter Sizes (3x3, 5x5, 7x7)',\n",
    "        'Decreasing Filter Sizes (7x7, 5x5, 3x3)',\n",
    "        'L1/L2 Regularization with Dropout',\n",
    "        'With Data Augmentation',\n",
    "        'Without Data Augmentation'\n",
    "    ],\n",
    "    'Validation Accuracy (%)': [81.94, 74.9, 56.18, 73.6, 72.94, 73.42, 77.6, 52.52],\n",
    "    'Testing Accuracy (%)': [83.82, 80.55, 65.49, 77.41, 78.81, 77.17, 78.53, 76.86]\n",
    "}\n",
    "\n",
    "# pandas dataframe\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Format to two decimal places\n",
    "formatted_results_df = results_df.style.format({\n",
    "    'Validation Accuracy (%)': '{:.2f}%',\n",
    "    'Testing Accuracy (%)': '{:.2f}%'\n",
    "}).set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('font-weight', 'bold')]}]\n",
    ").set_properties(**{'text-align': 'center'}).set_caption(\"Experimental Results Summary\")\n",
    "\n",
    "formatted_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiments with different CNN setups on the CIFAR-10 dataset, using small filters (3x3) resulted in the best performance, achieving a high testing accuracy of 80.55%. These filters effectively captured essential details. Data augmentation also played a crucial role by increasing testing accuracy to 78.53%, compared to 76.86% without it, highlighting its importance for generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt",
   "language": "python",
   "name": "opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
